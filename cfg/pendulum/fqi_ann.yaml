experiment: 
  type: experiment/batch_learning
  runs: 1
  batches: 0
  batch_size: 1000
  rate: 0
  model: 
    type: model/dynamical
    control_step: 0.03
    integration_steps: 5
    dynamics: 
      type: dynamics/pendulum
  task: 
    type: task/pendulum/swingup
    timeout: 2.99
    randomization: 0
  predictor: 
    type: predictor/fqi
    gamma: 0.97
    transitions: 100000
    iterations: 30
    reset_strategy: never
    macro_batch_size: 1
    discretizer: 
      type: discretizer/uniform
      min: experiment/task/action_min
      max: experiment/task/action_max
      steps: [3]
    projector: 
      type: projector/pre/normalizing
      input_min: experiment/task/observation_min++experiment/task/action_min
      input_max: experiment/task/observation_max++experiment/task/action_max
      projector: 
        type: projector/identity
    representation: 
      type: representation/iterative
      epochs: 5000
      cumulative: 0
      representation: 
        type: representation/parameterized/ann
        inputs: experiment/task/observation_dims+experiment/task/action_dims
        outputs: 1
        hiddens: [ 20 ]
        eta: 0
  test_agent: 
    type: agent/fixed
    policy: 
      type: mapping/policy/discrete/value/q
      discretizer: experiment/predictor/discretizer
      projector: experiment/predictor/projector
      representation: experiment/predictor/representation
      sampler: 
        type: sampler/greedy
  observation_min: experiment/task/observation_min
  observation_max: experiment/task/observation_max
  action_min: experiment/task/action_min
  action_max: experiment/task/action_max
visualizer: 
  type: visualizer/glut
visualization: 
  type: visualization/field/policy/value
  field_dims: [0, 1]
  input_min: experiment/task/observation_min
  input_max: experiment/task/observation_max
  points: 16384
  savepoints: 1048576
  projection: mean
  policy: experiment/test_agent/policy
visualization2: 
  type: visualization/pendulum
  state: experiment/state
