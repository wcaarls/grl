experiment: 
  type: experiment/online_learning
  runs: 1
  trials: 100
  steps: 0
  rate: 30
  test_interval: 0
  output: leosim_pid_squat
  environment: 
    type: environment/leo_squat
    target_env: 
      type: environment/ode
      xml: ../../leo/cfg/leo_learn_squatting.xml
      randomize: 0
      visualize: 1
    observe: hipright, hipleft, kneeright, kneeleft, ankleright, ankleleft, direction
    actuate: hipright, hipleft, kneeright, kneeleft, ankleright, ankleleft
    exporter: 
      type: exporter/csv
      file: leosim_pid_squat
      style: meshup
      variant: test
      split_runs: 1
    target_observations: robot.torso_boom.angle, robot.torso_boom.anglerate, robot.shoulder.angle, robot.shoulder.anglerate, robot.hipright.angle, robot.hipright.anglerate, robot.hipleft.angle, robot.hipleft.anglerate, robot.kneeright.angle, robot.kneeright.anglerate, robot.kneeleft.angle, robot.kneeleft.anglerate, robot.ankleright.angle, robot.ankleright.anglerate, robot.ankleleft.angle, robot.ankleleft.anglerate, robot.toeright.contact, robot.heelright.contact, robot.toeleft.contact, robot.heelleft.contact
    target_actions: robot.shoulder.voltage, robot.hipright.voltage, robot.hipleft.voltage, robot.kneeright.voltage, robot.kneeleft.voltage, robot.ankleright.voltage, robot.ankleleft.voltage
    frequency: 30
    target_observation_min: experiment/environment/target_env/observation_min
    target_observation_max: experiment/environment/target_env/observation_max
    target_action_min: experiment/environment/target_env/action_min
    target_action_max: experiment/environment/target_env/action_max
  agent: 
    type: agent/master/exclusive
    gamma: 0.97
    agent1: 
      type: agent/sub/compartmentalized
      min: [-3.1415, -3.1415, -3.1415, -3.1415, -3.1415, -3.1415, -31.4159, -31.4159, -31.4159, -31.4159, -31.4159, -31.4159, 0]
      max: [3.1415, 3.1415, 3.1415, 3.1415, 3.1415, 3.1415, 31.4159, 31.4159, 31.4159, 31.4159, 31.4159, 31.4159, 1]
      agent: 
        type: agent/fixed
        policy: 
          type: policy/parameterized/pid
          setpoint: [0.2, 0.2, -0.2, -0.2, 0.1, 0.1, 0, 0, 0, 0, 0, 0]
          outputs: 6
          p: [5.7, 0, 0, 0, 0, 0, 0, 5.7, 0, 0, 0, 0, 0, 0, 5.75, 0, 0, 0, 0, 0, 0, 5.75, 0, 0, 0, 0, 0, 0, 8.0, 0, 0, 0, 0, 0, 0, 8.0, 0.6, 0, 0, 0, 0, 0, 0, 0.6, 0, 0, 0, 0, 0, 0, 0.8, 0, 0, 0, 0, 0, 0, 0.8, 0, 0, 0, 0, 0, 0, 0.65, 0, 0, 0, 0, 0, 0, 0.65]
          i: []
          d: []
          il: []
    agent2: 
      type: agent/sub/compartmentalized
      min: [-3.1415, -3.1415, -3.1415, -3.1415, -3.1415, -3.1415, -31.4159, -31.4159, -31.4159, -31.4159, -31.4159, -31.4159, -1]
      max: [3.1415, 3.1415, 3.1415, 3.1415, 3.1415, 3.1415, 31.4159, 31.4159, 31.4159, 31.4159, 31.4159, 31.4159, 0]
      agent: 
        type: agent/fixed
        policy: 
          type: policy/parameterized/pid
          setpoint: [1.6, 1.6, -1.9, -1.9, 0.85, 0.85, 0, 0, 0, 0, 0, 0]
          outputs: 6
          p: [5.5, 0, 0, 0, 0, 0, 0, 5.5, 0, 0, 0, 0, 0, 0, 6.1, 0, 0, 0, 0, 0, 0, 6.1, 0, 0, 0, 0, 0, 0, 7.35, 0, 0, 0, 0, 0, 0, 7.35, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2.1, 0, 0, 0, 0, 0, 0, 2.1, 0, 0, 0, 0, 0, 0, 2.06, 0, 0, 0, 0, 0, 0, 2.06]
          i: []
          d: []
          il: []
  test_agent: experiment/agent
  save_every: never
