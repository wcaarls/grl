agent/black_box:
  description: Agent that learns from the cumulative reward of complete rollouts
  episodes:
    type: int
    description: Number of episodes to evaluate policy
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  optimizer:
    type: optimizer
    description: Policy optimizer
    mutability: configuration
    default: 0
    optional: 0
agent/communicator:
  description: Communicator agent which connects GRL to a remote agent
  communicator:
    type: communicator
    description: Comunicator which exchanges messages with an actual/virtual environment
    mutability: configuration
    default: 0
    optional: 0
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  action_min:
    type: vector.action_min
    description: Lower limit of action
    mutability: system
    default: "[  ]"
    optional: 1
  action_max:
    type: vector.action_max
    description: Upper limit of action
    mutability: system
    default: "[  ]"
    optional: 1
  test:
    type: int.test
    description: Selection of a learning/testing agent role
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 2147483647
agent/delayed_td:
  description: Agent that learns from observed state transitions assuming non-integer values of control delay
  policy:
    type: mapping/policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Value function predictor
    mutability: configuration
    default: 0
    optional: 0
  control_delay:
    type: double
    description: "Relative control delay: 0 (no delay) - 1 (one timestep delay) "
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
agent/dyna:
  description: Agent that learns from both observed and predicted state transitions
  planning_steps:
    type: int
    description: Number of planning steps per control step
    mutability: online
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  planning_horizon:
    type: int
    description: Planning episode length
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  threads:
    type: int
    description: Threads used for planning (0 = synchronous planning. >0 requires reentrant model_agent)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  policy:
    type: mapping/policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Value function predictor
    mutability: configuration
    default: 0
    optional: 0
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  model_predictor:
    type: predictor/model
    description: Model predictor
    mutability: configuration
    default: 0
    optional: 1
  model_agent:
    type: agent
    description: Agent used for planning episodes
    mutability: configuration
    default: 0
    optional: 0
  state:
    type: state
    description: Current observed state of planning
    mutability: provided
agent/filtering:
  description: Agent that filters incoming observations and outgoing actions
  observation_idx:
    type: vector
    description: Index vector for downstream observation (-1=pad)
    mutability: configuration
    default: "[  ]"
    optional: 1
  action_idx:
    type: vector
    description: Index vector for upstream action (-1=pad)
    mutability: configuration
    default: "[  ]"
    optional: 1
  action_dims:
    type: int
    description: Number of downstream action dimensions
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  agent:
    type: agent
    description: Downstream agent
    mutability: configuration
    default: 0
    optional: 0
agent/fixed:
  description: Fixed-policy agent
  policy:
    type: mapping/policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
agent/leo/fixed:
  description: Leo fixed agent
  policy:
    type: mapping/policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  pub_transition_type:
    type: signal/vector
    description: Publisher of the transition type
    mutability: configuration
    default: 0
    optional: 1
agent/leo/sma:
  description: State-machine agent for Leo
  agent_prepare:
    type: agent
    description: Prepare agent
    mutability: configuration
    default: 0
    optional: 0
  agent_standup:
    type: agent
    description: Safe standup agent
    mutability: configuration
    default: 0
    optional: 0
  agent_starter:
    type: agent
    description: Starting agent
    mutability: configuration
    default: 0
    optional: 1
  agent_main:
    type: agent
    description: Main agent
    mutability: configuration
    default: 0
    optional: 0
  upright_trigger:
    type: trigger
    description: Trigger which finishes stand-up phase and triggers preparation agent
    mutability: configuration
    default: 0
    optional: 0
  fc_trigger:
    type: trigger
    description: Trigger which checks for foot contact to ensure that robot is prepared to walk
    mutability: configuration
    default: 0
    optional: 0
  starter_trigger:
    type: trigger
    description: Trigger which initiates a preprogrammed walking at the beginning
    mutability: configuration
    default: 0
    optional: 1
  sub_ic_signal:
    type: signal/vector
    description: Subscriber to the contact signal
    mutability: configuration
    default: 0
    optional: 1
agent/leo/sym_wrapper:
  description: Leo agent that symmetrically wraps angles and controls
  agent:
    type: agent
    description: Target agent with reduced state-action space due to symmetry
    mutability: configuration
    default: 0
    optional: 0
  sub_ic_signal:
    type: signal/vector
    description: Publisher of the initialization and contact signal
    mutability: configuration
    default: 0
    optional: 0
agent/leo/td:
  description: Leo agent that learns from observed state transitions
  policy:
    type: mapping/policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Value function predictor
    mutability: configuration
    default: 0
    optional: 0
  pub_transition_type:
    type: signal/vector
    description: Publisher of the transition type
    mutability: configuration
    default: 0
    optional: 1
agent/leo_preprogrammed:
  description: Leo preprogrammed agent
  rand_gen:
    type: random_generator
    description: Random generator for action pertubation
    mutability: configuration
    default: 0
    optional: 0
  epsilon:
    type: double
    description: Exploration rate
    mutability: configuration
    default: 0.05
    optional: 1
    min: 0
    max: 1
  output_min:
    type: vector.action_min
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
agent/master/exclusive:
  description: Master agent that selects one sub-agent to execute
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  control_step:
    type: double.control_step
    description: Characteristic step time on which gamma is defined
    mutability: system
    default: 0.05
    optional: 1
    min: 0
    max: 1
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  agent:
    type: "[agent/sub]"
    description: Subagents
    mutability: configuration
    default: 0xdd5448
    optional: 0
agent/master/predicated:
  description: Master agent in which execution is predicated on preceding agent confidence
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  control_step:
    type: double.control_step
    description: Characteristic step time on which gamma is defined
    mutability: system
    default: 0.05
    optional: 1
    min: 0
    max: 1
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  agent:
    type: "[agent/sub]"
    description: Subagents
    mutability: configuration
    default: 0xdd5448
    optional: 0
agent/master/random:
  description: Master agent that chooses sub-agents randomly
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  control_step:
    type: double.control_step
    description: Characteristic step time on which gamma is defined
    mutability: system
    default: 0.05
    optional: 1
    min: 0
    max: 1
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  agent:
    type: "[agent/sub]"
    description: Subagents
    mutability: configuration
    default: 0xdd5448
    optional: 0
agent/master/sequential:
  description: Master agent that executes sub-agents sequentially
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  agent1:
    type: agent
    description: First subagent, providing the suggested action
    mutability: configuration
    default: 0
    optional: 0
  agent2:
    type: agent
    description: Second subagent, providing the final action
    mutability: configuration
    default: 0
    optional: 0
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
agent/master/sequential/additive:
  description: Additive master agent that executes sub-agents sequentially and adds their outputs
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  agent1:
    type: agent
    description: First subagent, providing the suggested action
    mutability: configuration
    default: 0
    optional: 0
  agent2:
    type: agent
    description: Second subagent, providing the final action
    mutability: configuration
    default: 0
    optional: 0
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  output_min:
    type: vector.action_min
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
agent/remapping:
  description: Agent that remaps actions
  mapping:
    type: mapping
    description: Maps downstream observation-action pairs onto upstream actions
    mutability: configuration
    default: 0
    optional: 0
  agent:
    type: agent
    description: Downstream agent
    mutability: configuration
    default: 0
    optional: 0
agent/replay:
  description: Agent that learns from batches of stored transitions
  replay_steps:
    type: int
    description: Number of replay steps per control step
    mutability: online
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  batch_size:
    type: int
    description: Number of replay steps per batch
    mutability: online
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  threads:
    type: int
    description: Threads used for replay (0 = synchronous replay. >0 requires reentrant predictor)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  policy:
    type: mapping/policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Value function predictor
    mutability: configuration
    default: 0
    optional: 0
agent/solver:
  description: Agent that successively solves learned models of the environment
  interval:
    type: int
    description: Episodes between successive solutions (0=asynchronous)
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  policy:
    type: mapping/policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Optional (model) predictor
    mutability: configuration
    default: 0
    optional: 1
  solver:
    type: solver
    description: Model-based solver
    mutability: configuration
    default: 0
    optional: 0
agent/sub/compartmentalized:
  description: Sub agent that is valid in a fixed state-space region
  min:
    type: vector.observation_min
    description: Minimum of compartment bounding box
    mutability: configuration
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max
    description: Maximum of compartment bounding box
    mutability: configuration
    default: "[  ]"
    optional: 1
  agent:
    type: agent
    description: Sub agent
    mutability: configuration
    default: 0
    optional: 0
agent/sub/filtering:
  description: Subagent that filters incoming observations and outgoing actions
  observation_idx:
    type: vector
    description: Index vector for downstream observation (-1=pad)
    mutability: configuration
    default: "[  ]"
    optional: 1
  action_idx:
    type: vector
    description: Index vector for upstream action (-1=pad)
    mutability: configuration
    default: "[  ]"
    optional: 1
  action_dims:
    type: int
    description: Number of downstream action dimensions
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  agent:
    type: agent/sub
    description: Downstream subagent
    mutability: configuration
    default: 0
    optional: 0
agent/sub/voluntary:
  description: Sub agent that has confidence as part of the action
  dim:
    type: int
    description: Action dimension that indicates confidence
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  agent:
    type: agent
    description: Sub agent
    mutability: configuration
    default: 0
    optional: 0
agent/td:
  description: Agent that learns from observed state transitions
  policy:
    type: mapping/policy
    description: Control policy
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Value function predictor
    mutability: configuration
    default: 0
    optional: 0
behavior/leo_squat_sym:
  description: Leo squatting behavior with symmetrical switchers of observations
behavior/leo_walk:
  description: Leo walking behavior without symmetrical switchers of observations
behavior/leo_walk_sym:
  description: Leo walking behavior with symmetrical switchers of observations
communicator/zeromq/pub_sub:
  description: Zeromq class to establish a link by sending messages asynchronously (publisher/subscriber)
  role:
    type: string
    description: Role of the zeromq (Pub/Sub, Request/Reply)
    mutability: configuration
    default: ""
    optional: 1
    options:
      - NONE
      - ZMQ_SUB
      - ZMQ_PUB
      - ZMQ_REQ
      - ZMQ_REP
  sync:
    type: string
    description: Syncronization ip address
    mutability: configuration
    default: ""
    optional: 1
  pub:
    type: string
    description: Publisher address
    mutability: configuration
    default: tcp://*:5561
    optional: 1
  sub:
    type: string
    description: subscriber address
    mutability: configuration
    default: tcp://192.168.1.10:5562
    optional: 1
communicator/zeromq/request_reply:
  description: Zeromq class to establish a link by sending messages synchronously (request/reply)
  role:
    type: string
    description: Role of the zeromq (Pub/Sub, Request/Reply)
    mutability: configuration
    default: ""
    optional: 1
    options:
      - NONE
      - ZMQ_SUB
      - ZMQ_PUB
      - ZMQ_REQ
      - ZMQ_REP
  sync:
    type: string
    description: Syncronization ip address
    mutability: configuration
    default: ""
    optional: 1
  addr:
    type: string
    description: Address
    mutability: configuration
    default: tcp://localhost:5555
    optional: 1
converter/state_action_converter:
  description: Configurable which is capable of remapping states and actions
  state_in:
    type: string
    description: Comma-separated list of state elements in the input vector
    mutability: configuration
    default: ""
    optional: 1
  state_out:
    type: string
    description: Comma-separated list of state elements in the output vector
    mutability: configuration
    default: ""
    optional: 1
  action_in:
    type: string
    description: Comma-separated list of action elements observed in the input vector
    mutability: configuration
    default: ""
    optional: 1
  action_out:
    type: string
    description: Comma-separated list of action elements provided in the output vector
    mutability: configuration
    default: ""
    optional: 1
discretizer/peaked:
  description: Peaked discretizer, with more resolution around center
  min:
    type: vector
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
discretizer/policy:
  description: Returns the action suggested by a policy
  policy:
    type: mapping/policy
    description: Policy whose action to return
    mutability: configuration
    default: 0
    optional: 0
discretizer/split:
  description: Compound discretizer
  identify:
    type: int
    description: Identify active discretizer before (-1) or after (1) value
    mutability: configuration
    default: -1
    optional: 1
    min: -1
    max: 1
  discretizer1:
    type: discretizer.
    description: First discretizer
    mutability: configuration
    default: 0
    optional: 0
  discretizer2:
    type: discretizer.
    description: Second discretizer
    mutability: configuration
    default: 0
    optional: 1
discretizer/uniform:
  description: Uniform discretizer
  min:
    type: vector
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
dynamics/acrobot:
  description: Acrobot dynamics
dynamics/cart_double_pole:
  description: Cart-double-pole dynamics from Zhong and Rock
dynamics/cart_pole:
  description: Cart-pole dynamics from Barto et al.
  end_stop:
    type: int
    description: Simulate end stops (adds position and velocity to state)
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
dynamics/flyer2d:
  description: 2D flyer dynamics
dynamics/mountain:
  description: Mountain world dynamics
  mass:
    type: double
    description: Car mass
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  gravity:
    type: double
    description: Gravitational acceleration
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  friction:
    type: double
    description: Coefficient of viscous friction between car and ground
    mutability: configuration
    default: 0.05
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  stiffness:
    type: double
    description: Spring constant of walls
    mutability: configuration
    default: 1000
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  map:
    type: mapping
    description: Height map
    mutability: configuration
    default: 0
    optional: 0
dynamics/pendulum:
  description: Pendulum dynamics based on the DCSC MOPS
dynamics/rbdl:
  description: RBDL rigid body dynamics
  file:
    type: string
    description: RBDL Lua model file
    mutability: configuration
    default: ""
    optional: 1
  options:
    type: string
    description: Lua string to execute when loading model
    mutability: configuration
    default: ""
    optional: 1
  points:
    type: string
    description: Points
    mutability: configuration
    default: ""
    optional: 1
  auxiliary:
    type: string
    description: Model mass(mm), Center of mass (com), Center of mass velocity (comv), Angular momentum (am)
    mutability: configuration
    default: ""
    optional: 1
dynamics/swimmer:
  description: Coulom's swimmer dynamics
  segments:
    type: double.swimmer/segments
    description: Number of swimmer segments
    mutability: configuration
    default: 2
    optional: 1
    min: 2
    max: 2147483647
dynamics/tlm:
  description: Two-link manipulator dynamics
environment/communicator:
  description: Communicator environment which interects with a real environment by sending and receiving messages
  converter:
    type: converter
    description: Convert states and actions if needed
    mutability: configuration
    default: 0
    optional: 1
  communicator:
    type: communicator
    description: Comunicator which exchanges messages with an actual/virtual environment
    mutability: configuration
    default: 0
    optional: 0
  target_obs_dims:
    type: int
    description: Observation dimension of a target
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  target_action_dims:
    type: int
    description: Action dimension of a target
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  benchmark_delays:
    type: int
    description: Observation dimension of a target
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 2147483647
environment/leo_squat:
  description: Leo squatting environment
  behavior:
    type: behavior
    description: Behavior type
    mutability: configuration
    default: 0
    optional: 0
  xml:
    type: string
    description: XML configuration filename
    mutability: configuration
    default: ""
    optional: 1
  target_env:
    type: environment
    description: Interaction environment
    mutability: configuration
    default: 0
    optional: 0
  observe:
    type: string
    description: Comma-separated list of state elements observed by an agent
    mutability: configuration
    default: ""
    optional: 1
  actuate:
    type: string
    description: Comma-separated list of action elements provided by an agent
    mutability: configuration
    default: ""
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  sub_transition_type:
    type: signal/vector
    description: Subscriber to the transition type
    mutability: configuration
    default: 0
    optional: 1
  pub_ic_signal:
    type: signal/vector
    description: Publisher of the initialization and contact signal
    mutability: configuration
    default: 0
    optional: 1
  measurement_noise:
    type: double
    description: Additive measurement noise
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
environment/leo_walk:
  description: Leo walking environment
  behavior:
    type: behavior
    description: Behavior type
    mutability: configuration
    default: 0
    optional: 0
  xml:
    type: string
    description: XML configuration filename
    mutability: configuration
    default: ""
    optional: 1
  target_env:
    type: environment
    description: Interaction environment
    mutability: configuration
    default: 0
    optional: 0
  observe:
    type: string
    description: Comma-separated list of state elements observed by an agent
    mutability: configuration
    default: ""
    optional: 1
  actuate:
    type: string
    description: Comma-separated list of action elements provided by an agent
    mutability: configuration
    default: ""
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  sub_transition_type:
    type: signal/vector
    description: Subscriber to the transition type
    mutability: configuration
    default: 0
    optional: 1
  pub_ic_signal:
    type: signal/vector
    description: Publisher of the initialization and contact signal
    mutability: configuration
    default: 0
    optional: 1
  measurement_noise:
    type: double
    description: Additive measurement noise
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
environment/modeled:
  description: Environment that uses a state transition model internally
  model:
    type: model
    description: Environment model
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to perform in the environment (should match model)
    mutability: configuration
    default: 0
    optional: 0
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  state:
    type: signal/vector.state
    description: Current state of the model
    mutability: provided
  action:
    type: signal/vector.action
    description: Last action applied to the model
    mutability: provided
environment/ode:
  description: Open Dynamics Engine simulation environment
  xml:
    type: string
    description: XML configuration filename
    mutability: configuration
    default: ../addons/odesim/cfg/robot.xml
    optional: 1
  randomize:
    type: int
    description: Randomize initial state
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  visualize:
    type: int
    description: Whether to display 3D visualization
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
environment/pre/noise:
  description: Injects noise into an environment
  environment:
    type: environment
    description: Environment to inject noise into
    mutability: configuration
    default: 0
    optional: 0
  sensor_noise:
    type: vector
    description: Additive sensor noise standard deviation
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  actuator_noise:
    type: vector
    description: Additive actuator noise standard deviation
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
environment/pre/shaping:
  description: Adds reward shaping to an environment
  environment:
    type: environment
    description: Environment to inject noise into
    mutability: configuration
    default: 0
    optional: 0
  shaping_function:
    type: mapping
    description: Potential function over states
    mutability: configuration
    default: 0
    optional: 0
  gamma:
    type: double
    description: Discount factor
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
environment/sandbox:
  description: Non-Markov environment
  model:
    type: sandbox_model
    description: Environment model
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to perform in the environment (should match model)
    mutability: configuration
    default: 0
    optional: 0
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  state:
    type: signal/vector
    description: Current state of the model
    mutability: provided
experiment/approx_test:
  description: Approximator test experiment (supervised learning)
  train_samples:
    type: int
    description: Number of training samples
    mutability: configuration
    default: 1000
    optional: 1
    min: 1
    max: 2147483647
  test_samples:
    type: int
    description: Number of test samples
    mutability: configuration
    default: 1000
    optional: 1
    min: 1
    max: 2147483647
  file:
    type: string
    description: Output file (csv format)
    mutability: configuration
    default: ""
    optional: 1
  input_min:
    type: vector
    description: Lower limit for drawing samples
    mutability: configuration
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper limit for drawing samples
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector
    description: Projector (should match representation)
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation
    description: Learned representation
    mutability: configuration
    default: 0
    optional: 0
  mapping:
    type: mapping
    description: Function to learn
    mutability: configuration
    default: 0
    optional: 0
experiment/batch_learning:
  description: Batch learning experiment using randomly sampled experience
  runs:
    type: int
    description: Number of separate learning runs to perform
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  batches:
    type: int
    description: Number of batches per learning run
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  batch_size:
    type: int
    description: Number of transitions per batch
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  rate:
    type: int
    description: Test trial control step frequency in Hz
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  output:
    type: string
    description: Output base filename
    mutability: configuration
    default: ""
    optional: 1
  model:
    type: model
    description: Model in which the task is set
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to be solved
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Learner
    mutability: configuration
    default: 0
    optional: 0
  test_agent:
    type: agent
    description: Agent to use in test trials after each batch
    mutability: configuration
    default: 0
    optional: 0
  observation_min:
    type: vector.observation_min
    description: Lower limit for observations
    mutability: system
    default: "[  ]"
    optional: 1
  observation_max:
    type: vector.observation_max
    description: Upper limit for observations
    mutability: system
    default: "[  ]"
    optional: 1
  action_min:
    type: vector.action_min
    description: Lower limit for actions
    mutability: system
    default: "[  ]"
    optional: 1
  action_max:
    type: vector.action_max
    description: Upper limit for actions
    mutability: system
    default: "[  ]"
    optional: 1
  state:
    type: signal/vector
    description: Current observed state of the environment
    mutability: provided
experiment/multi:
  description: Run multiple experiments in parallel
  instances:
    type: int
    description: Number of experiments to run in parallel
    mutability: configuration
    default: 4
    optional: 1
    min: 1
    max: 2147483647
  experiment:
    type: experiment
    description: Experiment to run
    mutability: configuration
    default: 0
    optional: 0
experiment/online_learning:
  description: Interactive learning experiment
  runs:
    type: int
    description: Number of separate learning runs to perform
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  run_offset:
    type: int
    description: Run offset to start at
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  trials:
    type: int
    description: Number of episodes per learning run
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  steps:
    type: int
    description: Number of steps per learning run
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  rate:
    type: int
    description: Control step frequency in Hz
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  test_interval:
    type: int
    description: Number of episodes in between test trials
    mutability: configuration
    default: -1
    optional: 1
    min: -1
    max: 2147483647
  output:
    type: string
    description: Output base filename
    mutability: configuration
    default: ""
    optional: 1
  environment:
    type: environment
    description: Environment in which the agent acts
    mutability: configuration
    default: 0
    optional: 0
  agent:
    type: agent
    description: Agent
    mutability: configuration
    default: 0
    optional: 0
  test_agent:
    type: agent
    description: Agent to use in test trials
    mutability: configuration
    default: 0
    optional: 1
  state:
    type: signal/vector.observation
    description: Current observed state of the environment
    mutability: provided
  action:
    type: signal/vector.action
    description: Last action applied to the environment
    mutability: provided
  curve:
    type: signal/vector
    description: Learning curve
    mutability: provided
  load_file:
    type: string
    description: Load policy filename
    mutability: configuration
    default: ""
    optional: 1
  save_every:
    type: string
    description: Save policy to 'output' at the end of event
    mutability: configuration
    default: never
    optional: 1
    options:
      - never
      - run
      - test
      - trail
experiment/rpc/environment:
  description: Environment RPC server
  port:
    type: int
    description: Listen port
    mutability: configuration
    default: 31033
    optional: 1
    min: 0
    max: 2147483647
  environment:
    type: environment
    description: Environment to interface
    mutability: configuration
    default: 0
    optional: 0
exporter/csv:
  description: Comma-separated values exporter
  file:
    type: string
    description: Output base filename
    mutability: configuration
    default: ""
    optional: 1
  fields:
    type: string
    description: Comma-separated list of fields to write
    mutability: configuration
    default: ""
    optional: 1
  style:
    type: string
    description: Header style
    mutability: configuration
    default: line
    optional: 1
    options:
      - none
      - line
      - meshup
  variant:
    type: string
    description: Variant to export
    mutability: configuration
    default: all
    optional: 1
    options:
      - test
      - learn
      - all
  enabled:
    type: int
    description: Enable writing to output file
    mutability: online
    default: 1
    optional: 1
    min: 0
    max: 1
importer/csv:
  description: Comma-separated values importer
  file:
    type: string
    description: Input base filename
    mutability: configuration
    default: ""
    optional: 1
  fields:
    type: string
    description: Comma-separated list of fields to read
    mutability: configuration
    default: ""
    optional: 1
mapping/displacement:
  description: Mapping that returns the state displacement effected by a policy
  policy:
    type: mapping/policy
    description: Policy for which displacement is calculated
    mutability: configuration
    default: 0
    optional: 0
  model:
    type: observation_model
    description: Observation model on which policy acts
    mutability: configuration
    default: 0
    optional: 0
mapping/expanding:
  description: Mapping that expands discrete into continuous actions
  policy:
    type: mapping/policy
    description: Optional policy used to calculate action
    mutability: configuration
    default: 0
    optional: 1
  discretizer:
    type: discretizer.action
    description: Discretizer to convert discrete into continuous action
    mutability: configuration
    default: 0
    optional: 0
mapping/filtering:
  description: Mapping that filters inputs and outputs
  input_idx:
    type: vector
    description: Index vector for downstream inputs (-1=pad)
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_idx:
    type: vector
    description: Index vector for upstream outputs (-1=pad)
    mutability: configuration
    default: "[  ]"
    optional: 1
  mapping:
    type: mapping
    description: Downstream mapping
    mutability: configuration
    default: 0
    optional: 0
mapping/image:
  description: Mapping read from an ICS image file
  file:
    type: string
    description: ICS image file name
    mutability: configuration
    default: ""
    optional: 1
  min:
    type: vector
    description: Lower domain limit
    mutability: configuration
    default: "[ 0, 0 ]"
    optional: 1
  max:
    type: vector
    description: Upper domain limit
    mutability: configuration
    default: "[ 1, 1 ]"
    optional: 1
mapping/multisine:
  description: Sum of sines mapping
  inputs:
    type: int
    description: Number of input dimensions
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int
    description: Number of output dimensions
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  sines:
    type: int
    description: Number of sines
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
mapping/policy/action:
  description: Policy based on a direct action representation
  sigma:
    type: vector
    description: Standard deviation of exploration distribution
    mutability: configuration
    default: "[  ]"
    optional: 1
  decay_rate:
    type: double
    description: Multiplicative decay factor per episode
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  decay_min:
    type: double
    description: Minimum decay (sigma_min = sigma*decay_min)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  output_min:
    type: vector.action_min
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.action
    description: Action representation
    mutability: configuration
    default: 0
    optional: 0
mapping/policy/action_probability:
  description: Policy based on an action-probability representation
  discretizer:
    type: discretizer
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Action-probability representation
    mutability: configuration
    default: 0
    optional: 0
mapping/policy/discrete/random:
  description: Policy that chooses discrete random actions
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
mapping/policy/feed_forward:
  description: Feed-forward policy
  controls:
    type: mapping
    description: Maps time to controls
    mutability: configuration
    default: 0
    optional: 1
mapping/policy/filtering:
  description: Policy that filters observations and actions
  observation_idx:
    type: vector
    description: Index vector for downstream observations (-1=pad)
    mutability: configuration
    default: "[  ]"
    optional: 1
  action_idx:
    type: vector
    description: Index vector for upstream actions (-1=pad)
    mutability: configuration
    default: "[  ]"
    optional: 1
  policy:
    type: mapping/policy
    description: Downstream policy
    mutability: configuration
    default: 0
    optional: 0
mapping/policy/mcts:
  description: Monte-Carlo Tree Search policy
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  epsilon:
    type: double
    description: Exploration rate
    mutability: online
    default: 0.05
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  horizon:
    type: int
    description: Planning horizon
    mutability: online
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  budget:
    type: double
    description: Computational budget
    mutability: online
    default: 0.05
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  trajectory:
    type: signal/matrix
    description: Predicted trajectory
    mutability: provided
mapping/policy/multi:
  description: Combines multiple policies
  strategy:
    type: string
    description: Combination strategy
    mutability: configuration
    default: ""
    optional: 1
    options:
      - policy_strategy_add_prob
      - policy_strategy_multiply_prob
      - policy_strategy_majority_voting_prob
      - policy_strategy_rank_voting_prob
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0x64
    optional: 0
  policy:
    type: "[mapping/policy]"
    description: Sub-policies
    mutability: configuration
    default: 0xf54090
    optional: 0
mapping/policy/parameterized/action:
  description: Parameterized policy based on a direct action representation
  sigma:
    type: vector
    description: Standard deviation of exploration distribution
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_min:
    type: vector.action_min
    description: Lower limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper limit on outputs
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation/parameterized.action
    description: Action representation
    mutability: configuration
    default: 0
    optional: 0
mapping/policy/parameterized/pid:
  description: Parameterized policy based on a proportional-integral-derivative controller
  setpoint:
    type: vector
    description: Setpoint
    mutability: online
    default: "[  ]"
    optional: 1
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  p:
    type: vector
    description: P gains ([out1_in1, ..., out1_inN, ..., outN_in1, ..., outN_inN])
    mutability: online
    default: "[  ]"
    optional: 1
  i:
    type: vector
    description: I gains
    mutability: online
    default: "[  ]"
    optional: 1
  d:
    type: vector
    description: D gains (use P gain on velocity instead, if available)
    mutability: online
    default: "[  ]"
    optional: 1
  il:
    type: vector
    description: Integration limits
    mutability: online
    default: "[  ]"
    optional: 1
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: system
    default: "[  ]"
    optional: 1
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: system
    default: "[  ]"
    optional: 1
mapping/policy/parameterized/pidt:
  description: Parameterized policy based on a proportional-integral-derivative controller for trajectory tracking
  trajectory:
    type: mapping
    description: Maps time to setpoints
    mutability: configuration
    default: 0
    optional: 0
  inputs:
    type: int.observation_dims
    description: Number of inputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  p:
    type: vector
    description: P gains ([out1_in1, ..., out1_inN, ..., outN_in1, ..., outN_inN])
    mutability: online
    default: "[  ]"
    optional: 1
  i:
    type: vector
    description: I gains
    mutability: online
    default: "[  ]"
    optional: 1
  d:
    type: vector
    description: D gains (use P gain on velocity instead, if available)
    mutability: online
    default: "[  ]"
    optional: 1
  il:
    type: vector
    description: Integration limits
    mutability: online
    default: "[  ]"
    optional: 1
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: system
    default: "[  ]"
    optional: 1
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: system
    default: "[  ]"
    optional: 1
mapping/policy/parameterized/state_feedback:
  description: Parameterized policy based on a state feedback controller
  operating_state:
    type: vector
    description: Operating state around which gains are defined
    mutability: configuration
    default: "[  ]"
    optional: 1
  operating_action:
    type: vector
    description: Operating action around which gains are defined
    mutability: configuration
    default: "[  ]"
    optional: 1
  gains:
    type: vector
    description: Gains ([in1_out1, ..., in1_outN, ..., inN_out1, ..., inN_outN])
    mutability: online
    default: "[  ]"
    optional: 1
  output_min:
    type: vector.action_min
    description: Lower action limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper action limit
    mutability: system
    default: "[  ]"
    optional: 1
mapping/policy/post/noise:
  description: Postprocesses policy output by injecting noise
  sigma:
    type: vector
    description: Standard deviation of Gaussian exploration distribution
    mutability: configuration
    default: "[  ]"
    optional: 1
  theta:
    type: vector
    description: Ornstein-Uhlenbeck friction term (1=pure Gaussian noise)
    mutability: configuration
    default: "[  ]"
    optional: 1
  policy:
    type: mapping/policy
    description: Policy to inject noise into
    mutability: configuration
    default: 0
    optional: 0
mapping/policy/random:
  description: Policy that chooses continuous random actions
  output_min:
    type: vector.action_min
    description: Lower action limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper action limit
    mutability: system
    default: "[  ]"
    optional: 1
mapping/policy/sample_feedback:
  description: Policy based on state feedback controller defined over samples
  output_min:
    type: vector.action_min
    description: Lower action limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper action limit
    mutability: system
    default: "[  ]"
    optional: 1
mapping/policy/uct:
  description: Monte-Carlo Tree Search policy using UCB1 action selection
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  epsilon:
    type: double
    description: Exploration rate
    mutability: online
    default: 0.05
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  horizon:
    type: int
    description: Planning horizon
    mutability: online
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  budget:
    type: double
    description: Computational budget
    mutability: online
    default: 0.05
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  trajectory:
    type: signal/matrix
    description: Predicted trajectory
    mutability: provided
mapping/policy/value/q:
  description: Q-value based policy
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Action-value representation
    mutability: configuration
    default: 0
    optional: 0
  sampler:
    type: sampler
    description: Samples actions from action-values
    mutability: configuration
    default: 0
    optional: 0
mapping/policy/value/q/bounded:
  description: Q-value based policy with bounded action deltas
  bound:
    type: vector
    description: Maximum action delta
    mutability: configuration
    default: "[  ]"
    optional: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Action-value representation
    mutability: configuration
    default: 0
    optional: 0
  sampler:
    type: sampler
    description: Samples actions from action-values
    mutability: configuration
    default: 0
    optional: 0
mapping/policy/value/q/ucb:
  description: UCB1 policy
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Q-value representation
    mutability: configuration
    default: 0
    optional: 0
  visit_representation:
    type: representation.value/action
    description: Visit count representation
    mutability: configuration
    default: 0
    optional: 0
  c_p:
    type: double
    description: UCB1 exploration term
    mutability: online
    default: 1.41421
    optional: 1
    min: 0
    max: 1.797693134862316e+308
mapping/policy/value/v:
  description: State-value based policy
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  model:
    type: observation_model
    description: Observation model
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/state
    description: State-value representation
    mutability: configuration
    default: 0
    optional: 0
  sampler:
    type: sampler
    description: Samples actions from state-values
    mutability: configuration
    default: 0
    optional: 0
mapping/puddle:
  description: Random 2D puddles
  seed:
    type: int
    description: World seed
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  smoothing:
    type: double
    description: Standard deviation of Gaussian filter
    mutability: configuration
    default: 0.1
    optional: 1
    min: 0
    max: 1
  steepness:
    type: double
    description: Parameter of sigmoid stretching
    mutability: configuration
    default: 1
    optional: 1
    min: 1
    max: 50
mapping/represented:
  description: A mapping that internally uses a representation
  projector:
    type: projector
    description: Projects inputs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation
    description: Representation
    mutability: configuration
    default: 0
    optional: 0
mapping/timeline:
  description: Imported timeline mapping
  importer:
    type: importer.dynamic
    description: Importer with time as the first column
    mutability: configuration
    default: 0
    optional: 0
mapping/value:
  description: Mapping that returns the expected value of a value-based policy
  policy:
    type: mapping/policy/value
    description: Value based policy
    mutability: configuration
    default: 0
    optional: 0
model/compass_walker:
  description: Simplest walker model from Garcia et al.
  control_step:
    type: double.control_step
    description: Control step time
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  integration_steps:
    type: int
    description: Number of integration steps per control step
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: configuration
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
model/dynamical:
  description: State transition model that integrates equations of motion
  control_step:
    type: double.control_step
    description: Control step time
    mutability: configuration
    default: 0.05
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  integration_steps:
    type: int
    description: Number of integration steps per control step
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  dynamics:
    type: dynamics
    description: Equations of motion
    mutability: configuration
    default: 0
    optional: 0
model/pinball:
  description: Model of a ball on a plate
  control_step:
    type: double.control_step
    description: Control step time
    mutability: configuration
    default: 0.05
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  integration_steps:
    type: int
    description: Number of integration steps per control step
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  restitution:
    type: double
    description: Coefficient of restitution
    mutability: configuration
    default: 0.5
    optional: 1
    min: 0
    max: 1
  radius:
    type: double
    description: Ball radius
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  maze:
    type: int
    description: Maze ID
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
model/puddle:
  description: Puddle world model
  drag:
    type: double
    description: Velocity multiplier for puddles
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  map:
    type: mapping/puddle
    description: Puddle map
    mutability: configuration
    default: 0
    optional: 0
model/windy:
  description: Sutton & Barto's windy gridworld model
observation_model/approximated:
  description: Observation model based on observed transitions
  jacobian_step:
    type: double
    description: Step size for Jacobian estimation
    mutability: online
    default: 0.001
    optional: 1
    min: 2.225073858507201e-308
    max: 1.797693134862316e+308
  control_step:
    type: double.control_step
    description: Control step time (0 = estimate using SMDP approximator)
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  differential:
    type: vector.differential
    description: State dimensions for which to predict deltas
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries
    mutability: configuration
    default: "[  ]"
    optional: 1
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: system
    default: "[  ]"
    optional: 1
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: system
    default: "[  ]"
    optional: 1
  stddev_limit:
    type: double
    description: Maximum standard deviation of acceptable predictions, as fraction of range
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projector for transition model (|S|+|A| dimensions)
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.transition
    description: Representation for transition model (|S|+2 dimensions)
    mutability: configuration
    default: 0
    optional: 0
observation_model/fixed:
  description: Observation model based on known state transition model
  jacobian_step:
    type: double
    description: Step size for Jacobian estimation
    mutability: online
    default: 0.001
    optional: 1
    min: 2.225073858507201e-308
    max: 1.797693134862316e+308
  model:
    type: model
    description: Environment model
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to perform in the environment (should match model)
    mutability: configuration
    default: 0
    optional: 0
observation_model/fixed_reward:
  description: Observation model based on observed transitions but known task
  jacobian_step:
    type: double
    description: Step size for Jacobian estimation
    mutability: online
    default: 0.001
    optional: 1
    min: 2.225073858507201e-308
    max: 1.797693134862316e+308
  control_step:
    type: double.control_step
    description: Control step time (0 = estimate using SMDP approximator)
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  differential:
    type: vector.differential
    description: State dimensions for which to predict deltas
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries
    mutability: configuration
    default: "[  ]"
    optional: 1
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: system
    default: "[  ]"
    optional: 1
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: system
    default: "[  ]"
    optional: 1
  stddev_limit:
    type: double
    description: Maximum standard deviation of acceptable predictions, as fraction of range
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projector for transition model (|S|+|A| dimensions)
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.transition
    description: Representation for transition model (|S|+2 dimensions)
    mutability: configuration
    default: 0
    optional: 0
  task:
    type: task
    description: Task to perform in the environment
    mutability: configuration
    default: 0
    optional: 0
optimizer/cma:
  description: Coverance matrix adaptation black-box optimizer
  population:
    type: int
    description: Population size
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  sigma:
    type: vector
    description: Initial standard deviation (a single-element vector will be replicated for all parameters)
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  policy:
    type: mapping/policy/parameterized
    description: Control policy prototype
    mutability: configuration
    default: 0
    optional: 0
optimizer/rwa:
  description: Reward weighted averaging black-box optimizer
  mu:
    type: int
    description: Parent population size
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  lambda:
    type: int
    description: Offspring population size
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  sigma:
    type: vector
    description: Standard deviation of exploration
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  policy:
    type: mapping/policy/parameterized
    description: Control policy prototype
    mutability: configuration
    default: 0
    optional: 0
predictor/ac/action:
  description: Actor-critic predictor for direct action policies
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Critic learning rate
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  update_method:
    type: string
    description: Actor update method
    mutability: configuration
    default: proportional
    optional: 1
    options:
      - proportional
      - cacla
  step_limit:
    type: vector
    description: Actor exploration step limit
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Projects observations onto actor representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.action
    description: Action representation
    mutability: configuration
    default: 0
    optional: 0
  critic:
    type: predictor/critic
    description: Critic predictor
    mutability: configuration
    default: 0
    optional: 0
predictor/ac/action/expanded:
  description: Actor-critic predictor for expanded direct action policies
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Critic learning rate
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  update_method:
    type: string
    description: Actor update method
    mutability: configuration
    default: proportional
    optional: 1
    options:
      - proportional
      - cacla
  step_limit:
    type: vector
    description: Actor exploration step limit
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Projects observations onto actor representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.action
    description: Action representation
    mutability: configuration
    default: 0
    optional: 0
  critic:
    type: predictor/critic
    description: Critic predictor
    mutability: configuration
    default: 0
    optional: 0
  discrete_action:
    type: vector
    description: Discrete action that expands to continuous actor action
    mutability: configuration
    default: "[  ]"
    optional: 1
predictor/ac/probability:
  description: Actor-critic predictor for action-probability policies
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Critic learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  beta:
    type: double
    description: Actor learning rate
    mutability: configuration
    default: 0.1
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  critic_projector:
    type: projector.observation
    description: Projects observations onto critic representation space
    mutability: configuration
    default: 0
    optional: 0
  critic_representation:
    type: representation.value/state
    description: Value function representation
    mutability: configuration
    default: 0
    optional: 0
  critic_trace:
    type: trace
    description: Trace of critic projections
    mutability: configuration
    default: 0
    optional: 1
  actor_projector:
    type: projector.pair
    description: Projects observation-action pairs onto actor representation space
    mutability: configuration
    default: 0
    optional: 0
  actor_representation:
    type: representation.value/action
    description: Action-probability representation
    mutability: configuration
    default: 0
    optional: 0
  actor_trace:
    type: trace
    description: Trace of actor projections
    mutability: configuration
    default: 0
    optional: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
predictor/critic/advantage:
  description: Advantage learning off-policy value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  kappa:
    type: double
    description: Advantage scaling factor
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: A-value representation
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 1
predictor/critic/av:
  description: AV on-policy advantage function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: State-action advantage learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  beta:
    type: double
    description: State value learning rate
    mutability: configuration
    default: 0.1
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  a_projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  a_representation:
    type: representation.value/action
    description: State-action advantage representation (A)
    mutability: configuration
    default: 0
    optional: 0
  v_projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  v_representation:
    type: representation.value/state
    description: State value representation (V)
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 1
predictor/critic/expected_sarsa:
  description: Expected SARSA low-variance on-policy value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Q-value representation
    mutability: configuration
    default: 0
    optional: 0
  policy:
    type: mapping/policy/value
    description: Value based target policy
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 1
predictor/critic/ggq:
  description: Greedy-GQ off-policy value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  eta:
    type: double
    description: Relative secondary learning rate (actual is alpha*eta)
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: (Q, w) representation
    mutability: configuration
    default: 0
    optional: 0
  policy:
    type: mapping/policy/value
    description: Greedy target policy
    mutability: configuration
    default: 0
    optional: 0
predictor/critic/q:
  description: Q-learning off-policy value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Q-value representation
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 1
predictor/critic/qv:
  description: QV on-policy value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: State-action value learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  beta:
    type: double
    description: State value learning rate
    mutability: configuration
    default: 0.1
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  q_projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  q_representation:
    type: representation.value/action
    description: State-action value representation (Q)
    mutability: configuration
    default: 0
    optional: 0
  v_projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  v_representation:
    type: representation.value/state
    description: State value representation (V)
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 1
predictor/critic/sarsa:
  description: SARSA on-policy value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Q-value representation
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 1
predictor/critic/td:
  description: TD value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/state
    description: State value representation
    mutability: configuration
    default: 0
    optional: 0
  trace:
    type: trace
    description: Trace of projections
    mutability: configuration
    default: 0
    optional: 1
predictor/dpg:
  description: Deterministic policy gradient predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: Advantage model learning rate
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1
  beta_v:
    type: double
    description: Critic learning rate
    mutability: configuration
    default: 0.1
    optional: 1
    min: 0
    max: 1
  beta_a:
    type: double
    description: Actor learning rate
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  lambda:
    type: double
    description: Trace decay rate
    mutability: configuration
    default: 0.65
    optional: 1
    min: 0
    max: 1
  target:
    type: string
    description: Policy target
    mutability: configuration
    default: on-policy
    optional: 1
    options:
      - on-policy
      - off-policy
  projector:
    type: projector.observation
    description: Projects observations onto representation spaces
    mutability: configuration
    default: 0
    optional: 0
  critic_representation:
    type: representation.value/state
    description: State value function representation
    mutability: configuration
    default: 0
    optional: 0
  critic_trace:
    type: trace
    description: Trace of critic projections
    mutability: configuration
    default: 0
    optional: 1
  advantage_representation:
    type: representation
    description: Local advantage model representation (one output per action dimension)
    mutability: configuration
    default: 0
    optional: 0
  actor_representation:
    type: representation.action
    description: Action representation
    mutability: configuration
    default: 0
    optional: 0
predictor/fqi:
  description: Fitted Q-iteration predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  transitions:
    type: int
    description: Maximum number of transitions to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 1
    max: 2147483647
  iterations:
    type: int
    description: Number of policy improvement rounds per episode
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  reset_strategy:
    type: string
    description: At which point to reset the representation
    mutability: configuration
    default: iteration
    optional: 1
    options:
      - never
      - batch
      - iteration
  macro_batch_size:
    type: int
    description: Number of episodes/batches after which prediction is rebuilt. Use 0 for no rebuilds.
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observations onto critic representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Value function representation
    mutability: configuration
    default: 0
    optional: 0
predictor/full/qi:
  description: Deterministic model-based action-value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Action-value function representation
    mutability: configuration
    default: 0
    optional: 0
predictor/full/vi:
  description: Deterministic model-based state-value function predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/state
    description: State-value function representation
    mutability: configuration
    default: 0
    optional: 0
predictor/lspi:
  description: Least Squares Policy Iteration predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  transitions:
    type: int
    description: Maximum number of transitions to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 1
    max: 2147483647
  iterations:
    type: int
    description: Number of policy improvement rounds per episode
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  macro_batch_size:
    type: int
    description: Number of episodes/batches after which prediction is rebuilt. Use 0 for no rebuilds.
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observations-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Linear value function representation
    mutability: configuration
    default: 0
    optional: 0
predictor/mbfqi:
  description: Minibatch FQI predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  transitions:
    type: int
    description: Maximum number of transitions to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 1
    max: 2147483647
  minibatch_size:
    type: int
    description: Number of transitions to average gradient over.
    mutability: configuration
    default: 64
    optional: 1
    min: 0
    max: 2147483647
  update_interval:
    type: int
    description: Number of minibatches between target updates.
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  discretizer:
    type: discretizer
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector.pair
    description: Projects observations onto critic representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Value function representation
    mutability: configuration
    default: 0
    optional: 0
predictor/model:
  description: Observation model predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  differential:
    type: vector.differential
    description: State dimensions for which to predict deltas
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.pair
    description: Projector for transition model (|S|+|A| dimensions)
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.transition
    description: Representation for transition model (|S|+2 dimensions)
    mutability: configuration
    default: 0
    optional: 0
predictor/multi:
  description: Updates multiple predictors
  predictor:
    type: "[predictor]"
    description: First downstream predictor
    mutability: configuration
    default: 0x1150c90
    optional: 0
predictor/naf:
  description: Value function predictor using Normalized Advantage Features
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.pair
    description: Projects observation-action pairs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.value/action
    description: Combined (action, state value) representation
    mutability: configuration
    default: 0
    optional: 0
predictor/reinforce:
  description: Monte-Carlo Policy Gradient predictor
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  alpha:
    type: double
    description: learning rate
    mutability: configuration
    default: 0.1
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate
    mutability: configuration
    default: 0.97
    optional: 1
    min: 0
    max: 1
  projector:
    type: projector.observation
    description: Projects observations onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation.action
    description: Policy representation
    mutability: configuration
    default: 0
    optional: 0
predictor/snapping:
  description: Snaps updates to grid centers
  importer:
    type: importer.static
    description: Optional importer for pre-training
    mutability: configuration
    default: 0
    optional: 1
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports observation, action, reward, next_observation, next_action)
    mutability: configuration
    default: 0
    optional: 1
  input_min:
    type: vector.observation_min
    description: Lower observation dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max
    description: Upper observation dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Centers per observation dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  centers:
    type: int
    description: Number of closest centers to snap to (0=all)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor
    description: Downstream predictor
    mutability: configuration
    default: 0
    optional: 0
projector/fourier:
  description: Fourier basis function projector
  input_min:
    type: vector
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  order:
    type: int
    description: Order of approximation (bases per dimension)
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 256
  parity:
    type: string
    description: Whether to use odd or even bases
    mutability: configuration
    default: even
    optional: 1
    options:
      - even
      - odd
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/grid/index:
  description: Discretizes continuous input to a linear grid index
  discretizer:
    type: discretizer
    description: Discretizer
    mutability: configuration
    default: 0
    optional: 0
  memory:
    type: int.memory
    description: Grid size
    mutability: provided
projector/grid/position:
  description: Discretizes continuous input to a grid center position
  discretizer:
    type: discretizer
    description: Discretizer
    mutability: configuration
    default: 0
    optional: 0
  memory:
    type: int.memory
    description: Grid size
    mutability: provided
projector/identity:
  description: Simply returns the input vector
projector/monomial:
  description: Monomial basis function projector
  operating_input:
    type: vector
    description: Origin
    mutability: configuration
    default: "[  ]"
    optional: 1
  degree:
    type: int
    description: Maximum degree of monomials
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 10
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/multi:
  description: Combines multiple projections
  dim:
    type: int
    description: Indicator dimension (-1=union)
    mutability: configuration
    default: -1
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: "[projector.]"
    description: Downstream projectors
    mutability: configuration
    default: 0x11a5b40
    optional: 0
  memories:
    type: vector.memory
    description: Memory of downstream projectors
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/pre/normalizing:
  description: Preprocesses projection onto a normalized [0, 1] vector
  input_min:
    type: vector
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/peaked:
  description: Preprocesses projection for more resolution around center
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/scaling:
  description: Preprocesses projection onto a scaled vector
  scaling:
    type: vector
    description: Scaling vector
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/rbf/gauss:
  description: Projection on a grid of Gaussian radial basis functions
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Basis functions per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
  sigma:
    type: double
    description: Standard deviation normalized to rbf spacing
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  cutoff:
    type: double
    description: Activation cutoff
    mutability: configuration
    default: 0.001
    optional: 1
    min: 0
    max: 1
projector/rbf/triangle:
  description: Projection on a grid of triangular radial basis functions
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Basis functions per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/sample/ann:
  description: Projects onto samples found through approximate nearest-neighbor search
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 1000
    optional: 1
    min: 100
    max: 2147483647
  neighbors:
    type: int
    description: Number of neighbors to return
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 64
  locality:
    type: double
    description: Locality of weighing function
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  interval:
    type: int
    description: Samples to accumulate before rebuilding kd-tree
    mutability: online
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  incremental:
    type: int
    description: Search samples that haven't been indexed yet
    mutability: online
    default: 1
    optional: 1
    min: 0
    max: 1
  bucket_size:
    type: int
    description: "?"
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  error_bound:
    type: double
    description: "?"
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  inputs:
    type: int
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/sample/ertree:
  description: Projects onto samples found through the Extra-trees algorithm by Geurts et al.
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 100
    max: 2147483647
  trees:
    type: int
    description: Number of trees in the forest
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  splits:
    type: int
    description: Number of candidate splits
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  leaf_size:
    type: int
    description: Maximum number of samples in a leaf
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  inputs:
    type: int
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/split:
  description: Splits a feature vector into distinct sets
  index:
    type: vector
    description: Binary vector that specifies which dimensions to use as index
    mutability: configuration
    default: "[  ]"
    optional: 1
  discretizer:
    type: discretizer
    description: Determines the distinct set based on the index dimensions
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector
    description: Projects the non-index dimensions onto a feature vector
    mutability: configuration
    default: 0
    optional: 0
  projector_memory:
    type: int.memory
    description: Memory of downstream projector
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Resulting feature vector size
    mutability: provided
projector/tile_coding:
  description: Hashed tile coding projector
  tilings:
    type: int
    description: Number of tilings
    mutability: configuration
    default: 16
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Hash table size
    mutability: configuration
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  safe:
    type: int
    description: Collision detection (0=off, 1=claim on write, 2=claim always)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2
  resolution:
    type: vector
    description: Size of a single tile
    mutability: configuration
    default: "[  ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries (must be multiple of resolution)
    mutability: configuration
    default: "[  ]"
    optional: 1
random_generator/normal:
  description: Normal Random generator
  mu:
    type: double
    description: Mean
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  sigma:
    type: double
    description: Standart deviation
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
random_generator/ornstein_uhlenbeck:
  description: Ornstein-Uhlenbeck Random generator
  center:
    type: double
    description: Attraction point
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  theta:
    type: double
    description: Theta
    mutability: configuration
    default: 0.05
    optional: 1
    min: 0
    max: 1
  sigma:
    type: double
    description: Sigma
    mutability: configuration
    default: 0.15
    optional: 1
    min: 0
    max: 1
random_generator/uniform:
  description: Uniform Random generator
  lower:
    type: double
    description: Lower bound of an interval
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  upper:
    type: double
    description: Upper bound of an interval
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
random_generator/uniform_integer:
  description: Uniform Integer Random generator
  ma:
    type: int
    description: Upper bound of an interval [0, ma)
    mutability: configuration
    default: 10
    optional: 1
    min: 0
    max: 2147483647
representation/additive:
  description: Linear combination of two representations
  learning:
    type: int
    description: Which representation to learn (-1=all)
    mutability: configuration
    default: 0
    optional: 1
    min: -1
    max: 2147483647
  representation:
    type: "[representation.]"
    description: Downstream representations
    mutability: configuration
    default: 0x120b890
    optional: 0
representation/communicator:
  description: Interface to an out-of-process representation
  inputs:
    type: int
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  communicator:
    type: communicator
    description: Communicator which exchanges messages with the out-of-process representation
    mutability: configuration
    default: 0
    optional: 0
representation/dictionary:
  description: Stores examples as key-value pairs in a dictionary
representation/iterative:
  description: Representation that iteratively trains a sub-representation
  epochs:
    type: int
    description: Learning epochs
    mutability: configuration
    default: 5000
    optional: 1
    min: 0
    max: 2147483647
  cumulative:
    type: int
    description: Add to training set instead of replacing it
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  batch_size:
    type: int
    description: Batch size for gradient estimation (0=entire dataset)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  representation:
    type: representation.
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
representation/llr:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann:
  description: Parameterized artificial neural network representation
  inputs:
    type: int
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  hiddens:
    type: vector
    description: Number of hidden nodes per layer
    mutability: configuration
    default: "[ 5 ]"
    optional: 1
  eta:
    type: double
    description: Learning rate (0=RPROP, <0=RMSPROP)
    mutability: configuration
    default: 0.7
    optional: 1
    min: -2
    max: 2
representation/parameterized/linear:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
representation/target:
  description: Representation that periodically updates a target representation
  representation:
    type: representation/parameterized.
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
  interval:
    type: double
    description: Update interval (number of writes; 0=never update, <0=exp.mov.av.)
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  target:
    type: representation/parameterized.
    description: Target representation
    mutability: provided
sampler/ac_ornstein_ohlenbeck:
  description: Action-correlated maximum search with an Ornstein-Uhlenbeck random chance of non-maximums
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  theta:
    type: vector
    description: Theta parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  sigma:
    type: vector
    description: Sigma parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  center:
    type: vector
    description: Centering parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  pub_sub_ou_state:
    type: signal/vector
    description: Publisher and subscriber to the value of noise (or action in the ACOU case) of the Ornstein Uhlenbeck familiy of samplers
    mutability: configuration
    default: 0
    optional: 1
  epsilon:
    type: double
    description: Exploration rate
    mutability: online
    default: 0.05
    optional: 1
    min: 0
    max: 1
sampler/epsilon_greedy:
  description: Maximum search with a uniform random chance of non-maximums
  epsilon:
    type: vector
    description: Exploration rate (can be defined per action)
    mutability: online
    default: "[ 0.050000000000000003 ]"
    optional: 1
  decay_rate:
    type: double
    description: Multiplicative decay factor per episode
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  decay_min:
    type: double
    description: Minimum decay (eps_min = eps*decay_min)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
sampler/epsilon_ornstein_ohlenbeck:
  description: Exploitations are done by greedy action selection without constraints, as in e-greedy. Explorations are done with time-correlated noise, as it is in OU.
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  theta:
    type: vector
    description: Theta parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  sigma:
    type: vector
    description: Sigma parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  center:
    type: vector
    description: Centering parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  pub_sub_ou_state:
    type: signal/vector
    description: Publisher and subscriber to the value of noise (or action in the ACOU case) of the Ornstein Uhlenbeck familiy of samplers
    mutability: configuration
    default: 0
    optional: 1
  epsilon:
    type: double
    description: Exploration rate
    mutability: online
    default: 0.05
    optional: 1
    min: 0
    max: 1
sampler/epsilon_pada:
  description: exploitations are done by greedy action selection without constraints, as in e-greedy. Explorations are done with constrained set of actions, as it is in pada.
  epsilon:
    type: vector
    description: Exploration rate (can be defined per action)
    mutability: online
    default: "[ 0.050000000000000003 ]"
    optional: 1
  decay_rate:
    type: double
    description: Multiplicative decay factor per episode
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  decay_min:
    type: double
    description: Minimum decay (eps_min = eps*decay_min)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  delta:
    type: vector
    description: Delta of PADA
    mutability: configuration
    default: "[  ]"
    optional: 1
  pub_sub_pada_state:
    type: signal/vector
    description: Publisher and subscriber to the value of action of the PADA familiy of samplers
    mutability: configuration
    default: 0
    optional: 1
sampler/greedy:
  description: Maximum search
sampler/leo/action:
  description: Wrapper for an action sampler for Leo (can modify memory of samplers with memory at contact events)
  sampler:
    type: sampler
    description: Samples actions from action-values
    mutability: configuration
    default: 0
    optional: 0
  sub_ic_signal:
    type: signal/vector
    description: Subscrider to the initialization and contact signal
    mutability: configuration
    default: 0
    optional: 1
  pub_sub_sampler_state:
    type: signal/vector
    description: Publisher and subscriber of the sampler state with memory such as previous action, noise, etc.
    mutability: configuration
    default: 0
    optional: 1
sampler/ornstein_ohlenbeck:
  description: Maximum search with an Ornstein-Uhlenbeck random chance of non-maximums
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  theta:
    type: vector
    description: Theta parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  sigma:
    type: vector
    description: Sigma parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  center:
    type: vector
    description: Centering parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  pub_sub_ou_state:
    type: signal/vector
    description: Publisher and subscriber to the value of noise (or action in the ACOU case) of the Ornstein Uhlenbeck familiy of samplers
    mutability: configuration
    default: 0
    optional: 1
sampler/pada:
  description: Maximum search with a PADA random chance of non-maximums
  epsilon:
    type: vector
    description: Exploration rate (can be defined per action)
    mutability: online
    default: "[ 0.050000000000000003 ]"
    optional: 1
  decay_rate:
    type: double
    description: Multiplicative decay factor per episode
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  decay_min:
    type: double
    description: Minimum decay (eps_min = eps*decay_min)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  delta:
    type: vector
    description: Delta of PADA
    mutability: configuration
    default: "[  ]"
    optional: 1
  pub_sub_pada_state:
    type: signal/vector
    description: Publisher and subscriber to the value of action of the PADA familiy of samplers
    mutability: configuration
    default: 0
    optional: 1
sampler/pada_ornstein_ohlenbeck:
  description: "Explorations and exploitations are same as OU, but action is selected from a constrained set, as in PADA. "
  discretizer:
    type: discretizer.action
    description: Action discretizer
    mutability: configuration
    default: 0
    optional: 0
  theta:
    type: vector
    description: Theta parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  sigma:
    type: vector
    description: Sigma parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  center:
    type: vector
    description: Centering parameter of Ornstein-Uhlenbeck
    mutability: configuration
    default: "[  ]"
    optional: 1
  pub_sub_ou_state:
    type: signal/vector
    description: Publisher and subscriber to the value of noise (or action in the ACOU case) of the Ornstein Uhlenbeck familiy of samplers
    mutability: configuration
    default: 0
    optional: 1
  pada:
    type: sampler
    description: Pada sampler
    mutability: configuration
    default: 0
    optional: 0
  pub_new_action:
    type: signal/vector
    description: Publisher of the signal with noise
    mutability: configuration
    default: 0
    optional: 0
sampler/softmax:
  description: Softmax (Gibbs/Boltzmann) sampler
  tau:
    type: double
    description: Temperature of Boltzmann distribution
    mutability: online
    default: 1
    optional: 1
    min: 1e-06
    max: 100
sandbox_model/compass_walker:
  description: Simplest walker model from Garcia et al. with a sequential evaluation
  control_step:
    type: double.control_step
    description: Control step time
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  integration_steps:
    type: int
    description: Number of integration steps per control step
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: configuration
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  exporter:
    type: exporter
    description: Optional exporter for transition log (supports time, state, observation, action, reward, terminal)
    mutability: configuration
    default: 0
    optional: 1
  use_avg_velocity:
    type: int
    description: "Velocity type "
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
sandbox_model/leo_squatting:
  description: State transition model that integrates equations of motion and augments state vector with additional elements
  control_step:
    type: double.control_step
    description: Control step time
    mutability: configuration
    default: 0.05
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
  integration_steps:
    type: int
    description: Number of integration steps per control step
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  dynamics:
    type: dynamics/rbdl
    description: Equations of motion
    mutability: configuration
    default: 0
    optional: 0
  target_dof:
    type: int.target_dof
    description: Number of degrees of freedom of the target model
    mutability: configuration
    default: 4
    optional: 1
    min: 0
    max: 2147483647
  animation:
    type: string
    description: Save current state or full animation
    mutability: configuration
    default: ""
    optional: 1
    options:
      - nope
      - full
      - immediate
  target_env:
    type: environment
    description: Interaction environment
    mutability: configuration
    default: 0
    optional: 1
  lower_height:
    type: double.lower_height
    description: Lower bound of root height to switch direction
    mutability: configuration
    default: 0.28
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  upper_height:
    type: double.upper_height
    description: Upper bound of root height to switch direction
    mutability: configuration
    default: 0.35
    optional: 1
    min: 0
    max: 1.797693134862316e+308
signal/matrix:
  description: Matrix-based signal (trajectory, etc.)
signal/vector:
  description: Vector-based signal (state, observation, etc.)
solver/agent:
  description: Solver that uses a simulated agent
  steps:
    type: int
    description: Number of planning steps before solution is returned
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  horizon:
    type: int
    description: Planning episode length
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  start:
    type: vector
    description: Starting state for planning
    mutability: configuration
    default: "[  ]"
    optional: 1
  model:
    type: observation_model
    description: Observation model used for planning
    mutability: configuration
    default: 0
    optional: 0
  agent:
    type: agent
    description: Agent used for planning episodes
    mutability: configuration
    default: 0
    optional: 0
  state:
    type: state
    description: Current observed state of planning
    mutability: provided
solver/ilqg:
  description: Iterative Linear Quadratic Gaussian trajectory optimizer
  horizon:
    type: int
    description: Horizon
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  iterations:
    type: int
    description: Maximum number of iterations
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 2147483647
  stddev:
    type: vector
    description: Standard deviation of initial random action sequence
    mutability: configuration
    default: "[  ]"
    optional: 1
  regularization:
    type: string
    description: Regularization method
    mutability: configuration
    default: state
    optional: 1
    options:
      - none
      - state
      - controls
  model:
    type: observation_model
    description: Observation model
    mutability: configuration
    default: 0
    optional: 0
  policy:
    type: mapping/policy/sample_feedback
    description: Sample feedback policy to adjust
    mutability: configuration
    default: 0
    optional: 0
  trajectory:
    type: signal/matrix
    description: Predicted trajectory
    mutability: provided
solver/lqr:
  description: Linear Quadratic Regulator solver
  operating_state:
    type: vector
    description: Operating state around which to linearize
    mutability: configuration
    default: "[  ]"
    optional: 1
  operating_action:
    type: vector
    description: Operating action around which to linearize
    mutability: configuration
    default: "[  ]"
    optional: 1
  model:
    type: observation_model
    description: Observation model
    mutability: configuration
    default: 0
    optional: 0
  policy:
    type: mapping/policy/parameterized/state_feedback
    description: State feedback policy to adjust
    mutability: configuration
    default: 0
    optional: 0
solver/vi:
  description: Value iteration solver
  sweeps:
    type: int
    description: Number of planning sweeps before solution is returned
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  parallel:
    type: int
    description: Perform backups in parallel (requires reentrant representation)
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  discretizer:
    type: discretizer.observation
    description: State space discretizer
    mutability: configuration
    default: 0
    optional: 0
  predictor:
    type: predictor/full
    description: Predictor to iterate
    mutability: configuration
    default: 0
    optional: 0
task/acrobot/balancing:
  description: Acrobot balancing task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
task/acrobot/regulator:
  description: Acrobot regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 3.1415926535897931, 0, 0, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 3.1415926535897931, 0, 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.0050000000000000001, 0.0050000000000000001, 0, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 1, 0, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01 ]"
    optional: 1
  function:
    type: string
    description: Cost function style
    mutability: configuration
    default: quadratic
    optional: 1
    options:
      - quadratic
      - absolute
      - sqrt
  smoothing:
    type: double
    description: Cost function smoothing parameter
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
task/cart_double_pole/balancing:
  description: Cart-double-pole balancing task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
task/cart_double_pole/regulator:
  description: Cart-double-pole regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 0, 0, 0, 0, 0, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0, 0, 0, 0, 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.01, 0.01, 0.01, 0, 0, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 1, 1, 0, 0, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01 ]"
    optional: 1
  function:
    type: string
    description: Cost function style
    mutability: configuration
    default: quadratic
    optional: 1
    options:
      - quadratic
      - absolute
      - sqrt
  smoothing:
    type: double
    description: Cost function smoothing parameter
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
task/cart_double_pole/swingup:
  description: Cart-double-pole swing-up task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
task/cart_pole/balancing:
  description: Cart-pole balancing task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
task/cart_pole/regulator:
  description: Cart-pole regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 0, 0, 0, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0, 0, 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.10000000000000001, 0.10000000000000001, 0, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 1, 0, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01 ]"
    optional: 1
  function:
    type: string
    description: Cost function style
    mutability: configuration
    default: quadratic
    optional: 1
    options:
      - quadratic
      - absolute
      - sqrt
  smoothing:
    type: double
    description: Cost function smoothing parameter
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
task/cart_pole/swingup:
  description: Cart-pole swing-up task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 9.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  randomization:
    type: int
    description: Start state randomization
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 1
  shaping:
    type: int
    description: Whether to use reward shaping
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  gamma:
    type: double
    description: Discount rate for reward shaping
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  end_stop_penalty:
    type: int
    description: Terminate episode with penalty when end stop is reached
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  action_penalty:
    type: int
    description: Penalize applied torque
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
task/compass_walker/vref:
  description: Compass walker tracking velocity task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Learning episode timeout
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  initial_state_variation:
    type: double
    description: Variation of initial state
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: system
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  negative_reward:
    type: double
    description: Negative reward
    mutability: configuration
    default: -100
    optional: 1
    min: -1.797693134862316e+308
    max: 0
  observe:
    type: vector
    description: State elements observed by an agent
    mutability: configuration
    default: "[ 1, 1, 1, 1, 1, 0, 0 ]"
    optional: 1
  steps:
    type: int
    description: number of steps after which task is terminated
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  reference_velocity:
    type: double
    description: Reference velocity
    mutability: configuration
    default: 0.12
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  per_step_reward:
    type: int
    description: If set, give reward per every step
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
task/compass_walker/vrefu:
  description: Compass walker tracking velocity task with controls minimization
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Learning episode timeout
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  initial_state_variation:
    type: double
    description: Variation of initial state
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: system
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  negative_reward:
    type: double
    description: Negative reward
    mutability: configuration
    default: -100
    optional: 1
    min: -1.797693134862316e+308
    max: 0
  observe:
    type: vector
    description: State elements observed by an agent
    mutability: configuration
    default: "[ 1, 1, 1, 1, 1, 0, 0 ]"
    optional: 1
  steps:
    type: int
    description: number of steps after which task is terminated
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  reference_velocity:
    type: double
    description: Reference velocity
    mutability: configuration
    default: 0.12
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  per_step_reward:
    type: int
    description: If set, give reward per every step
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
task/compass_walker/walk:
  description: Compass walker walking task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Learning episode timeout
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  initial_state_variation:
    type: double
    description: Variation of initial state
    mutability: configuration
    default: 0.2
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  slope_angle:
    type: double.slope_angle
    description: Inclination of the slope
    mutability: system
    default: 0.004
    optional: 1
    min: -1.797693134862316e+308
    max: 1.797693134862316e+308
  negative_reward:
    type: double
    description: Negative reward
    mutability: configuration
    default: -100
    optional: 1
    min: -1.797693134862316e+308
    max: 0
  observe:
    type: vector
    description: State elements observed by an agent
    mutability: configuration
    default: "[ 1, 1, 1, 1, 1, 0, 0 ]"
    optional: 1
  steps:
    type: int
    description: number of steps after which task is terminated
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
task/flyer2d/regulator:
  description: 2D flyer regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 0, 0, 0, 0, 0, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0, 0, 0, 0, 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.10000000000000001, 0.10000000000000001, 0.10000000000000001, 0, 0, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 1, 1, 0, 0, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01, 0.01 ]"
    optional: 1
  function:
    type: string
    description: Cost function style
    mutability: configuration
    default: quadratic
    optional: 1
    options:
      - quadratic
      - absolute
      - sqrt
  smoothing:
    type: double
    description: Cost function smoothing parameter
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  action_range:
    type: double
    description: Range of allowed actions
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 2.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
task/leo_squatting:
  description: Task specification for Leo squatting with a fixed arm
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double.timeout
    description: Task timeout
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  rand_init:
    type: int.rand_init
    description: Initialization from a random pose
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1
task/lua:
  description: User-provided task specification in LUA
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  file:
    type: string
    description: Lua task file
    mutability: configuration
    default: ""
    optional: 1
  options:
    type: string
    description: Lua string to execute when loading task
    mutability: configuration
    default: ""
    optional: 1
task/mountain/regulator:
  description: Mountain world regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 0.10000000000000001, 0.10000000000000001, 0, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0.90000000000000002, 0.90000000000000002, 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.10000000000000001, 0.10000000000000001, 0, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 1, 0, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01, 0.01 ]"
    optional: 1
  function:
    type: string
    description: Cost function style
    mutability: configuration
    default: quadratic
    optional: 1
    options:
      - quadratic
      - absolute
      - sqrt
  smoothing:
    type: double
    description: Cost function smoothing parameter
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
task/pendulum/regulator:
  description: Pendulum regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 3.1415926535897931, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.10000000000000001, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01 ]"
    optional: 1
  function:
    type: string
    description: Cost function style
    mutability: configuration
    default: quadratic
    optional: 1
    options:
      - quadratic
      - absolute
      - sqrt
  smoothing:
    type: double
    description: Cost function smoothing parameter
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
task/pendulum/swingup:
  description: Pendulum swing-up task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 2.99
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  randomization:
    type: double
    description: Level of start state randomization
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
task/pinball/movement:
  description: Pinball movement task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  tolerance:
    type: double
    description: Goal tolerance
    mutability: configuration
    default: 0.05
    optional: 1
    min: 0.001
    max: 1.797693134862316e+308
task/pinball/regulator:
  description: Pinball regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 0.10000000000000001, 0.10000000000000001, 0, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0.90000000000000002, 0.90000000000000002, 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.01, 0.01, 0, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 5, 1, 0, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01, 0.01 ]"
    optional: 1
  function:
    type: string
    description: Cost function style
    mutability: configuration
    default: quadratic
    optional: 1
    options:
      - quadratic
      - absolute
      - sqrt
  smoothing:
    type: double
    description: Cost function smoothing parameter
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
task/puddle/regulator:
  description: Puddle world regulator task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  start:
    type: vector
    description: Starting state
    mutability: configuration
    default: "[ 0.10000000000000001, 0.10000000000000001, 0, 0 ]"
    optional: 1
  goal:
    type: vector
    description: Goal state
    mutability: configuration
    default: "[ 0.90000000000000002, 0.90000000000000002, 0, 0 ]"
    optional: 1
  stddev:
    type: vector
    description: Starting state standard deviation
    mutability: configuration
    default: "[ 0.10000000000000001, 0.10000000000000001, 0, 0 ]"
    optional: 1
  q:
    type: vector
    description: Q (state cost) matrix diagonal
    mutability: configuration
    default: "[ 1, 1, 0, 0 ]"
    optional: 1
  r:
    type: vector
    description: R (action cost) matrix diagonal
    mutability: configuration
    default: "[ 0.01, 0.01 ]"
    optional: 1
  function:
    type: string
    description: Cost function style
    mutability: configuration
    default: quadratic
    optional: 1
    options:
      - quadratic
      - absolute
      - sqrt
  smoothing:
    type: double
    description: Cost function smoothing parameter
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1
  penalty:
    type: double
    description: Penalty multiplier for puddles
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  map:
    type: mapping/puddle
    description: Puddle map
    mutability: configuration
    default: 0
    optional: 1
task/swimmer/reaching:
  description: Swimmer reaching task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
  timeout:
    type: double
    description: Episode timeout
    mutability: configuration
    default: 20
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  randomization:
    type: double
    description: Level of start state randomization
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 1
  segments:
    type: double.swimmer/segments
    description: Number of swimmer segments
    mutability: system
    default: 2
    optional: 1
    min: 2
    max: 2147483647
task/tlm/balancing:
  description: Two-link manipulator balancing task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
task/windy/movement:
  description: Windy gridworld movement task
  observation_dims:
    type: int.observation_dims
    description: Number of observation dimensions
    mutability: provided
  observation_min:
    type: vector.observation_min
    description: Lower limit on observations
    mutability: provided
  observation_max:
    type: vector.observation_max
    description: Upper limit on observations
    mutability: provided
  action_dims:
    type: int.action_dims
    description: Number of action dimensions
    mutability: provided
  action_min:
    type: vector.action_min
    description: Lower limit on actions
    mutability: provided
  action_max:
    type: vector.action_max
    description: Upper limit on actions
    mutability: provided
  reward_min:
    type: double.reward_min
    description: Lower limit on immediate reward
    mutability: provided
  reward_max:
    type: double.reward_max
    description: Upper limit on immediate reward
    mutability: provided
trace/enumerated/accumulating:
  description: Accumulating eligibility trace using a queue of projections
trace/enumerated/replacing:
  description: Replacing eligibility trace using a queue of projections
trigger:
  description: Event trigger
  min:
    type: vector.observation_min
    description: Minimum of compartment bounding box
    mutability: configuration
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max
    description: Maximum of compartment bounding box
    mutability: configuration
    default: "[  ]"
    optional: 1
  delay:
    type: double
    description: Settlement delay for which conditions are continuously fullfilled
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 1.797693134862316e+308
visualization/acrobot:
  description: Acrobot visualization
  state:
    type: signal/vector
    description: Acrobot state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/cart_double_pole:
  description: Cart-double-pole visualization
  state:
    type: signal/vector
    description: Cart-double-pole state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/cart_pole:
  description: Cart-pole visualization
  state:
    type: signal/vector
    description: Cart-pole state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/compass_walker:
  description: Compass walker visualization
  state:
    type: signal/vector
    description: Compass walker state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/field/mapping:
  description: Visualizes a mapping over a field of states
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: online
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  points:
    type: int
    description: Number of points to evaluate
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  savepoints:
    type: int
    description: Number of points to evaluate when saving to file ('s')
    mutability: configuration
    default: 1048576
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: signal/vector
    description: Optional current state to overlay
    mutability: configuration
    default: 0
    optional: 1
  projection:
    type: string
    description: Method of projecting values onto 2d space
    mutability: online
    default: mean
    optional: 1
    options:
      - mean
      - min
      - max
  mapping:
    type: mapping
    description: Mapping
    mutability: configuration
    default: 0
    optional: 0
  output_dim:
    type: int
    description: Output dimension to visualize
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
visualization/field/policy/value:
  description: Visualizes the value of a policy over a field of states
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: online
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  points:
    type: int
    description: Number of points to evaluate
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  savepoints:
    type: int
    description: Number of points to evaluate when saving to file ('s')
    mutability: configuration
    default: 1048576
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: signal/vector
    description: Optional current state to overlay
    mutability: configuration
    default: 0
    optional: 1
  projection:
    type: string
    description: Method of projecting values onto 2d space
    mutability: online
    default: mean
    optional: 1
    options:
      - mean
      - min
      - max
  policy:
    type: mapping/policy/value
    description: Value based control policy
    mutability: configuration
    default: 0
    optional: 0
visualization/field/value:
  description: Visualizes an approximation over a field of states
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: online
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  points:
    type: int
    description: Number of points to evaluate
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  savepoints:
    type: int
    description: Number of points to evaluate when saving to file ('s')
    mutability: configuration
    default: 1048576
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: signal/vector
    description: Optional current state to overlay
    mutability: configuration
    default: 0
    optional: 1
  projection:
    type: string
    description: Method of projecting values onto 2d space
    mutability: online
    default: mean
    optional: 1
    options:
      - mean
      - min
      - max
  output_dim:
    type: int
    description: Output dimension to visualize
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: projector
    description: Projects inputs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation
    description: Value representation
    mutability: configuration
    default: 0
    optional: 0
visualization/flyer2d:
  description: 2D flyer visualization
  state:
    type: signal/vector
    description: 2D flyer state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/pendulum:
  description: Pendulum visualization
  state:
    type: signal/vector
    description: Pendulum state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/pinball:
  description: Pinball visualization
  state:
    type: signal/vector
    description: Pinball state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/sample:
  description: Visualizes a sample-based approximation
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: configuration
    default: "[ 0, 1 ]"
    optional: 1
  field_min:
    type: vector
    description: Lower visualization dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  field_max:
    type: vector
    description: Upper visualization dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_dim:
    type: int
    description: Output dimension to visualize
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  points:
    type: int
    description: Texture size
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: projector/sample
    description: Sample projector whose store to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/sample/random:
  description: Visualizes an approximation over randomly sampled states
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: configuration
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_dim:
    type: int
    description: Output dimension to visualize
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  points:
    type: int
    description: Texture size
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: projector
    description: Projects inputs onto representation space
    mutability: configuration
    default: 0
    optional: 0
  representation:
    type: representation
    description: Value representation
    mutability: configuration
    default: 0
    optional: 0
visualization/slice:
  description: Visualizes a slice from a mapping
  field_dims:
    type: vector
    description: Dimensions to visualize
    mutability: online
    default: "[ 0, 1 ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  operating_point:
    type: vector
    description: Fixed values for non-visualized dimensions
    mutability: online
    default: "[  ]"
    optional: 1
  output_dim:
    type: int
    description: Output dimension to visualize
    mutability: online
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  points:
    type: int
    description: Number of points to evaluate
    mutability: configuration
    default: 65536
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: signal/vector
    description: Optional current state to overlay
    mutability: configuration
    default: 0
    optional: 1
  action:
    type: signal/vector
    description: Optional current action to overlay
    mutability: configuration
    default: 0
    optional: 1
  mapping:
    type: mapping
    description: Mapping to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/state:
  description: Plots state values
  input_dims:
    type: vector
    description: Input dimensions to visualize
    mutability: online
    default: "[  ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  memory:
    type: int
    description: Number of data points to draw
    mutability: online
    default: 256
    optional: 1
    min: 0
    max: 2147483647
  state:
    type: signal/vector
    description: State to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/swimmer:
  description: Swimmer visualization
  state:
    type: signal/vector
    description: Swimmer state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/tlm:
  description: Two-link manipulator visualization
  state:
    type: signal/vector
    description: Two-link manipulator state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/trajectory:
  description: Plots trajectories
  input_dims:
    type: vector
    description: Input dimensions to visualize
    mutability: online
    default: "[  ]"
    optional: 1
  input_min:
    type: vector
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  trajectory:
    type: signal/matrix
    description: Trajectory to visualize
    mutability: configuration
    default: 0
    optional: 0
visualization/windy:
  description: Windy gridworld visualization
  state:
    type: signal/vector
    description: Windy gridworld state to visualize
    mutability: configuration
    default: 0
    optional: 0
visualizer/glut:
  description: Visualizer based on the GLUT library
signal/vector.state:
  description: Vector-based signal (state, observation, etc.)
signal/vector.action:
  description: Vector-based signal (state, observation, etc.)
signal/vector.observation:
  description: Vector-based signal (state, observation, etc.)
discretizer/peaked.action:
  description: Peaked discretizer, with more resolution around center
  min:
    type: vector.action_min
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.action_max
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
discretizer/policy.action:
  description: Returns the action suggested by a policy
  policy:
    type: mapping/policy
    description: Policy whose action to return
    mutability: configuration
    default: 0
    optional: 0
discretizer/split.action:
  description: Compound discretizer
  identify:
    type: int
    description: Identify active discretizer before (-1) or after (1) value
    mutability: configuration
    default: -1
    optional: 1
    min: -1
    max: 1
  discretizer1:
    type: discretizer.action
    description: First discretizer
    mutability: configuration
    default: 0
    optional: 0
  discretizer2:
    type: discretizer.action
    description: Second discretizer
    mutability: configuration
    default: 0
    optional: 1
discretizer/uniform.action:
  description: Uniform discretizer
  min:
    type: vector.action_min
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.action_max
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
projector/fourier.observation:
  description: Fourier basis function projector
  input_min:
    type: vector.observation_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  order:
    type: int
    description: Order of approximation (bases per dimension)
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 256
  parity:
    type: string
    description: Whether to use odd or even bases
    mutability: configuration
    default: even
    optional: 1
    options:
      - even
      - odd
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/grid/index.observation:
  description: Discretizes continuous input to a linear grid index
  discretizer:
    type: discretizer.observation
    description: Discretizer
    mutability: configuration
    default: 0
    optional: 0
  memory:
    type: int.memory
    description: Grid size
    mutability: provided
projector/grid/position.observation:
  description: Discretizes continuous input to a grid center position
  discretizer:
    type: discretizer.observation
    description: Discretizer
    mutability: configuration
    default: 0
    optional: 0
  memory:
    type: int.memory
    description: Grid size
    mutability: provided
projector/identity.observation:
  description: Simply returns the input vector
projector/monomial.observation:
  description: Monomial basis function projector
  operating_input:
    type: vector
    description: Origin
    mutability: configuration
    default: "[  ]"
    optional: 1
  degree:
    type: int
    description: Maximum degree of monomials
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 10
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/multi.observation:
  description: Combines multiple projections
  dim:
    type: int
    description: Indicator dimension (-1=union)
    mutability: configuration
    default: -1
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: "[projector.observation]"
    description: Downstream projectors
    mutability: configuration
    default: 0x153af60
    optional: 0
  memories:
    type: vector.memory
    description: Memory of downstream projectors
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/pre/normalizing.observation:
  description: Preprocesses projection onto a normalized [0, 1] vector
  input_min:
    type: vector.observation_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/peaked.observation:
  description: Preprocesses projection for more resolution around center
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
  input_min:
    type: vector.observation_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/scaling.observation:
  description: Preprocesses projection onto a scaled vector
  scaling:
    type: vector
    description: Scaling vector
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.observation
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/rbf/gauss.observation:
  description: Projection on a grid of Gaussian radial basis functions
  input_min:
    type: vector.observation_min
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Basis functions per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
  sigma:
    type: double
    description: Standard deviation normalized to rbf spacing
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  cutoff:
    type: double
    description: Activation cutoff
    mutability: configuration
    default: 0.001
    optional: 1
    min: 0
    max: 1
projector/rbf/triangle.observation:
  description: Projection on a grid of triangular radial basis functions
  input_min:
    type: vector.observation_min
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Basis functions per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/sample/ann.observation:
  description: Projects onto samples found through approximate nearest-neighbor search
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 1000
    optional: 1
    min: 100
    max: 2147483647
  neighbors:
    type: int
    description: Number of neighbors to return
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 64
  locality:
    type: double
    description: Locality of weighing function
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  interval:
    type: int
    description: Samples to accumulate before rebuilding kd-tree
    mutability: online
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  incremental:
    type: int
    description: Search samples that haven't been indexed yet
    mutability: online
    default: 1
    optional: 1
    min: 0
    max: 1
  bucket_size:
    type: int
    description: "?"
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  error_bound:
    type: double
    description: "?"
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/sample/ertree.observation:
  description: Projects onto samples found through the Extra-trees algorithm by Geurts et al.
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 100
    max: 2147483647
  trees:
    type: int
    description: Number of trees in the forest
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  splits:
    type: int
    description: Number of candidate splits
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  leaf_size:
    type: int
    description: Maximum number of samples in a leaf
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/split.observation:
  description: Splits a feature vector into distinct sets
  index:
    type: vector
    description: Binary vector that specifies which dimensions to use as index
    mutability: configuration
    default: "[  ]"
    optional: 1
  discretizer:
    type: discretizer
    description: Determines the distinct set based on the index dimensions
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector
    description: Projects the non-index dimensions onto a feature vector
    mutability: configuration
    default: 0
    optional: 0
  projector_memory:
    type: int.memory
    description: Memory of downstream projector
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Resulting feature vector size
    mutability: provided
projector/tile_coding.observation:
  description: Hashed tile coding projector
  tilings:
    type: int
    description: Number of tilings
    mutability: configuration
    default: 16
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Hash table size
    mutability: configuration
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  safe:
    type: int
    description: Collision detection (0=off, 1=claim on write, 2=claim always)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2
  resolution:
    type: vector
    description: Size of a single tile
    mutability: configuration
    default: "[  ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries (must be multiple of resolution)
    mutability: configuration
    default: "[  ]"
    optional: 1
representation/additive.action:
  description: Linear combination of two representations
  learning:
    type: int
    description: Which representation to learn (-1=all)
    mutability: configuration
    default: 0
    optional: 1
    min: -1
    max: 2147483647
  representation:
    type: "[representation.action]"
    description: Downstream representations
    mutability: configuration
    default: 0x158aa60
    optional: 0
representation/communicator.action:
  description: Interface to an out-of-process representation
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int.action_dims
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  communicator:
    type: communicator
    description: Communicator which exchanges messages with the out-of-process representation
    mutability: configuration
    default: 0
    optional: 0
representation/dictionary.action:
  description: Stores examples as key-value pairs in a dictionary
representation/iterative.action:
  description: Representation that iteratively trains a sub-representation
  epochs:
    type: int
    description: Learning epochs
    mutability: configuration
    default: 5000
    optional: 1
    min: 0
    max: 2147483647
  cumulative:
    type: int
    description: Add to training set instead of replacing it
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  batch_size:
    type: int
    description: Batch size for gradient estimation (0=entire dataset)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  representation:
    type: representation.action
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
representation/llr.action:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int.action_dims
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector.action_min
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample.observation
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann.action:
  description: Parameterized artificial neural network representation
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int.action_dims
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  hiddens:
    type: vector
    description: Number of hidden nodes per layer
    mutability: configuration
    default: "[ 5 ]"
    optional: 1
  eta:
    type: double
    description: Learning rate (0=RPROP, <0=RMSPROP)
    mutability: configuration
    default: 0.7
    optional: 1
    min: -2
    max: 2
representation/parameterized/linear.action:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int.action_dims
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector.action_min
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector.action_max
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
representation/target.action:
  description: Representation that periodically updates a target representation
  representation:
    type: representation/parameterized.action
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
  interval:
    type: double
    description: Update interval (number of writes; 0=never update, <0=exp.mov.av.)
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  target:
    type: representation/parameterized.action
    description: Target representation
    mutability: provided
projector/fourier.pair:
  description: Fourier basis function projector
  input_min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  order:
    type: int
    description: Order of approximation (bases per dimension)
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 256
  parity:
    type: string
    description: Whether to use odd or even bases
    mutability: configuration
    default: even
    optional: 1
    options:
      - even
      - odd
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/grid/index.pair:
  description: Discretizes continuous input to a linear grid index
  discretizer:
    type: discretizer.pair
    description: Discretizer
    mutability: configuration
    default: 0
    optional: 0
  memory:
    type: int.memory
    description: Grid size
    mutability: provided
projector/grid/position.pair:
  description: Discretizes continuous input to a grid center position
  discretizer:
    type: discretizer.pair
    description: Discretizer
    mutability: configuration
    default: 0
    optional: 0
  memory:
    type: int.memory
    description: Grid size
    mutability: provided
projector/identity.pair:
  description: Simply returns the input vector
projector/monomial.pair:
  description: Monomial basis function projector
  operating_input:
    type: vector
    description: Origin
    mutability: configuration
    default: "[  ]"
    optional: 1
  degree:
    type: int
    description: Maximum degree of monomials
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 10
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/multi.pair:
  description: Combines multiple projections
  dim:
    type: int
    description: Indicator dimension (-1=union)
    mutability: configuration
    default: -1
    optional: 1
    min: 0
    max: 2147483647
  projector:
    type: "[projector.pair]"
    description: Downstream projectors
    mutability: configuration
    default: 0x15e8330
    optional: 0
  memories:
    type: vector.memory
    description: Memory of downstream projectors
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/pre/normalizing.pair:
  description: Preprocesses projection onto a normalized [0, 1] vector
  input_min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.pair
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/peaked.pair:
  description: Preprocesses projection for more resolution around center
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
  input_min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit (for scaling)
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector.pair
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/pre/scaling.pair:
  description: Preprocesses projection onto a scaled vector
  scaling:
    type: vector
    description: Scaling vector
    mutability: configuration
    default: "[  ]"
    optional: 1
  projector:
    type: projector.pair
    description: Downstream projector
    mutability: configuration
    default: 0
    optional: 0
projector/rbf/gauss.pair:
  description: Projection on a grid of Gaussian radial basis functions
  input_min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Basis functions per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
  sigma:
    type: double
    description: Standard deviation normalized to rbf spacing
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  cutoff:
    type: double
    description: Activation cutoff
    mutability: configuration
    default: 0.001
    optional: 1
    min: 0
    max: 1
projector/rbf/triangle.pair:
  description: Projection on a grid of triangular radial basis functions
  input_min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  input_max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Basis functions per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: provided
projector/sample/ann.pair:
  description: Projects onto samples found through approximate nearest-neighbor search
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 1000
    optional: 1
    min: 100
    max: 2147483647
  neighbors:
    type: int
    description: Number of neighbors to return
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 64
  locality:
    type: double
    description: Locality of weighing function
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  interval:
    type: int
    description: Samples to accumulate before rebuilding kd-tree
    mutability: online
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  incremental:
    type: int
    description: Search samples that haven't been indexed yet
    mutability: online
    default: 1
    optional: 1
    min: 0
    max: 1
  bucket_size:
    type: int
    description: "?"
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  error_bound:
    type: double
    description: "?"
    mutability: configuration
    default: 0.01
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/sample/ertree.pair:
  description: Projects onto samples found through the Extra-trees algorithm by Geurts et al.
  samples:
    type: int
    description: Maximum number of samples to store
    mutability: configuration
    default: 100000
    optional: 1
    min: 100
    max: 2147483647
  trees:
    type: int
    description: Number of trees in the forest
    mutability: configuration
    default: 20
    optional: 1
    min: 1
    max: 2147483647
  splits:
    type: int
    description: Number of candidate splits
    mutability: configuration
    default: 5
    optional: 1
    min: 1
    max: 2147483647
  leaf_size:
    type: int
    description: Maximum number of samples in a leaf
    mutability: configuration
    default: 10
    optional: 1
    min: 1
    max: 2147483647
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 16
projector/split.pair:
  description: Splits a feature vector into distinct sets
  index:
    type: vector
    description: Binary vector that specifies which dimensions to use as index
    mutability: configuration
    default: "[  ]"
    optional: 1
  discretizer:
    type: discretizer
    description: Determines the distinct set based on the index dimensions
    mutability: configuration
    default: 0
    optional: 0
  projector:
    type: projector
    description: Projects the non-index dimensions onto a feature vector
    mutability: configuration
    default: 0
    optional: 0
  projector_memory:
    type: int.memory
    description: Memory of downstream projector
    mutability: system
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Resulting feature vector size
    mutability: provided
projector/tile_coding.pair:
  description: Hashed tile coding projector
  tilings:
    type: int
    description: Number of tilings
    mutability: configuration
    default: 16
    optional: 1
    min: 0
    max: 2147483647
  memory:
    type: int.memory
    description: Hash table size
    mutability: configuration
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  safe:
    type: int
    description: Collision detection (0=off, 1=claim on write, 2=claim always)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2
  resolution:
    type: vector
    description: Size of a single tile
    mutability: configuration
    default: "[  ]"
    optional: 1
  wrapping:
    type: vector.wrapping
    description: Wrapping boundaries (must be multiple of resolution)
    mutability: configuration
    default: "[  ]"
    optional: 1
representation/additive.value/action:
  description: Linear combination of two representations
  learning:
    type: int
    description: Which representation to learn (-1=all)
    mutability: configuration
    default: 0
    optional: 1
    min: -1
    max: 2147483647
  representation:
    type: "[representation.value/action]"
    description: Downstream representations
    mutability: configuration
    default: 0x1637890
    optional: 0
representation/communicator.value/action:
  description: Interface to an out-of-process representation
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  communicator:
    type: communicator
    description: Communicator which exchanges messages with the out-of-process representation
    mutability: configuration
    default: 0
    optional: 0
representation/dictionary.value/action:
  description: Stores examples as key-value pairs in a dictionary
representation/iterative.value/action:
  description: Representation that iteratively trains a sub-representation
  epochs:
    type: int
    description: Learning epochs
    mutability: configuration
    default: 5000
    optional: 1
    min: 0
    max: 2147483647
  cumulative:
    type: int
    description: Add to training set instead of replacing it
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  batch_size:
    type: int
    description: Batch size for gradient estimation (0=entire dataset)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  representation:
    type: representation.value/action
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
representation/llr.value/action:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample.pair
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann.value/action:
  description: Parameterized artificial neural network representation
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  hiddens:
    type: vector
    description: Number of hidden nodes per layer
    mutability: configuration
    default: "[ 5 ]"
    optional: 1
  eta:
    type: double
    description: Learning rate (0=RPROP, <0=RMSPROP)
    mutability: configuration
    default: 0.7
    optional: 1
    min: -2
    max: 2
representation/parameterized/linear.value/action:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
representation/target.value/action:
  description: Representation that periodically updates a target representation
  representation:
    type: representation/parameterized.value/action
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
  interval:
    type: double
    description: Update interval (number of writes; 0=never update, <0=exp.mov.av.)
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  target:
    type: representation/parameterized.value/action
    description: Target representation
    mutability: provided
representation/additive.value/state:
  description: Linear combination of two representations
  learning:
    type: int
    description: Which representation to learn (-1=all)
    mutability: configuration
    default: 0
    optional: 1
    min: -1
    max: 2147483647
  representation:
    type: "[representation.value/state]"
    description: Downstream representations
    mutability: configuration
    default: 0x1676610
    optional: 0
representation/communicator.value/state:
  description: Interface to an out-of-process representation
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  communicator:
    type: communicator
    description: Communicator which exchanges messages with the out-of-process representation
    mutability: configuration
    default: 0
    optional: 0
representation/dictionary.value/state:
  description: Stores examples as key-value pairs in a dictionary
representation/iterative.value/state:
  description: Representation that iteratively trains a sub-representation
  epochs:
    type: int
    description: Learning epochs
    mutability: configuration
    default: 5000
    optional: 1
    min: 0
    max: 2147483647
  cumulative:
    type: int
    description: Add to training set instead of replacing it
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  batch_size:
    type: int
    description: Batch size for gradient estimation (0=entire dataset)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  representation:
    type: representation.value/state
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
representation/llr.value/state:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample.observation
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann.value/state:
  description: Parameterized artificial neural network representation
  inputs:
    type: int.observation_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  hiddens:
    type: vector
    description: Number of hidden nodes per layer
    mutability: configuration
    default: "[ 5 ]"
    optional: 1
  eta:
    type: double
    description: Learning rate (0=RPROP, <0=RMSPROP)
    mutability: configuration
    default: 0.7
    optional: 1
    min: -2
    max: 2
representation/parameterized/linear.value/state:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
representation/target.value/state:
  description: Representation that periodically updates a target representation
  representation:
    type: representation/parameterized.value/state
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
  interval:
    type: double
    description: Update interval (number of writes; 0=never update, <0=exp.mov.av.)
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  target:
    type: representation/parameterized.value/state
    description: Target representation
    mutability: provided
importer/csv.dynamic:
  description: Comma-separated values importer
  file:
    type: string
    description: Input base filename
    mutability: configuration
    default: ""
    optional: 1
  fields:
    type: string
    description: Comma-separated list of fields to read
    mutability: configuration
    default: ""
    optional: 1
representation/additive.transition:
  description: Linear combination of two representations
  learning:
    type: int
    description: Which representation to learn (-1=all)
    mutability: configuration
    default: 0
    optional: 1
    min: -1
    max: 2147483647
  representation:
    type: "[representation.transition]"
    description: Downstream representations
    mutability: configuration
    default: 0x16c3410
    optional: 0
representation/communicator.transition:
  description: Interface to an out-of-process representation
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int.observation_dims+2
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  communicator:
    type: communicator
    description: Communicator which exchanges messages with the out-of-process representation
    mutability: configuration
    default: 0
    optional: 0
representation/dictionary.transition:
  description: Stores examples as key-value pairs in a dictionary
representation/iterative.transition:
  description: Representation that iteratively trains a sub-representation
  epochs:
    type: int
    description: Learning epochs
    mutability: configuration
    default: 5000
    optional: 1
    min: 0
    max: 2147483647
  cumulative:
    type: int
    description: Add to training set instead of replacing it
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  batch_size:
    type: int
    description: Batch size for gradient estimation (0=entire dataset)
    mutability: configuration
    default: 0
    optional: 1
    min: 0
    max: 2147483647
  representation:
    type: representation.transition
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
representation/llr.transition:
  description: Performs locally linear regression through samples
  ridge:
    type: double
    description: Ridge regression (Tikhonov) factor
    mutability: configuration
    default: 1e-05
    optional: 1
    min: 0
    max: 1
  order:
    type: int
    description: Order of regression model
    mutability: configuration
    default: 1
    optional: 1
    min: 0
    max: 1
  input_nominals:
    type: vector
    description: Vector indicating which input dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  output_nominals:
    type: vector
    description: Vector indicating which output dimensions are nominal
    mutability: configuration
    default: "[  ]"
    optional: 1
  outputs:
    type: int.observation_dims+2
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
  projector:
    type: projector/sample.pair
    description: Projector used to generate input for this representation
    mutability: configuration
    default: 0
    optional: 0
representation/parameterized/ann.transition:
  description: Parameterized artificial neural network representation
  inputs:
    type: int.observation_dims+int.action_dims
    description: Number of input dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  outputs:
    type: int.observation_dims+2
    description: Number of output dimensions
    mutability: system
    default: 1
    optional: 1
    min: 1
    max: 2147483647
  hiddens:
    type: vector
    description: Number of hidden nodes per layer
    mutability: configuration
    default: "[ 5 ]"
    optional: 1
  eta:
    type: double
    description: Learning rate (0=RPROP, <0=RMSPROP)
    mutability: configuration
    default: 0.7
    optional: 1
    min: -2
    max: 2
representation/parameterized/linear.transition:
  description: Linear-in-parameters representation
  init_min:
    type: vector
    description: Lower initial value limit
    mutability: configuration
    default: "[ 0 ]"
    optional: 1
  init_max:
    type: vector
    description: Upper initial value limit
    mutability: configuration
    default: "[ 1 ]"
    optional: 1
  memory:
    type: int.memory
    description: Feature vector size
    mutability: system
    default: 8388608
    optional: 1
    min: 0
    max: 2147483647
  outputs:
    type: int.observation_dims+2
    description: Number of outputs
    mutability: system
    default: 1
    optional: 1
    min: 0
    max: 2147483647
  output_min:
    type: vector
    description: Lower output limit
    mutability: system
    default: "[  ]"
    optional: 1
  output_max:
    type: vector
    description: Upper output limit
    mutability: system
    default: "[  ]"
    optional: 1
representation/target.transition:
  description: Representation that periodically updates a target representation
  representation:
    type: representation/parameterized.transition
    description: Downstream representation
    mutability: configuration
    default: 0
    optional: 0
  interval:
    type: double
    description: Update interval (number of writes; 0=never update, <0=exp.mov.av.)
    mutability: configuration
    default: 100
    optional: 1
    min: 0
    max: 1.797693134862316e+308
  target:
    type: representation/parameterized.transition
    description: Target representation
    mutability: provided
importer/csv.static:
  description: Comma-separated values importer
  file:
    type: string
    description: Input base filename
    mutability: configuration
    default: ""
    optional: 1
  fields:
    type: string
    description: Comma-separated list of fields to read (should be empty)
    mutability: configuration
    default: ""
    optional: 1
discretizer/peaked.observation:
  description: Peaked discretizer, with more resolution around center
  min:
    type: vector.observation_min
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
discretizer/policy.observation:
  description: Returns the action suggested by a policy
  policy:
    type: mapping/policy
    description: Policy whose action to return
    mutability: configuration
    default: 0
    optional: 0
discretizer/split.observation:
  description: Compound discretizer
  identify:
    type: int
    description: Identify active discretizer before (-1) or after (1) value
    mutability: configuration
    default: -1
    optional: 1
    min: -1
    max: 1
  discretizer1:
    type: discretizer.observation
    description: First discretizer
    mutability: configuration
    default: 0
    optional: 0
  discretizer2:
    type: discretizer.observation
    description: Second discretizer
    mutability: configuration
    default: 0
    optional: 1
discretizer/uniform.observation:
  description: Uniform discretizer
  min:
    type: vector.observation_min
    description: Lower limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max
    description: Upper limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
discretizer/peaked.pair:
  description: Peaked discretizer, with more resolution around center
  min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1
  peaking:
    type: vector
    description: Extra resolution factor around center (offset by 1/factor at edges)
    mutability: configuration
    default: "[  ]"
    optional: 1
discretizer/policy.pair:
  description: Returns the action suggested by a policy
  policy:
    type: mapping/policy
    description: Policy whose action to return
    mutability: configuration
    default: 0
    optional: 0
discretizer/split.pair:
  description: Compound discretizer
  identify:
    type: int
    description: Identify active discretizer before (-1) or after (1) value
    mutability: configuration
    default: -1
    optional: 1
    min: -1
    max: 1
  discretizer1:
    type: discretizer.pair
    description: First discretizer
    mutability: configuration
    default: 0
    optional: 0
  discretizer2:
    type: discretizer.pair
    description: Second discretizer
    mutability: configuration
    default: 0
    optional: 1
discretizer/uniform.pair:
  description: Uniform discretizer
  min:
    type: vector.observation_min+vector.action_min
    description: Lower input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  max:
    type: vector.observation_max+vector.action_max
    description: Upper input dimension limit
    mutability: system
    default: "[  ]"
    optional: 1
  steps:
    type: vector
    description: Discretization steps per dimension
    mutability: configuration
    default: "[  ]"
    optional: 1